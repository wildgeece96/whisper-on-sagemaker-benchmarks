{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd387845-cc83-4b60-8ca0-53c26fba0531",
   "metadata": {},
   "source": [
    "# Whisper for Inferentia2\n",
    "\n",
    "This sample shows how to compile & run Whisper models (different sizes) on Inferentia2. It makes use of the HF weights:  \n",
    "  - Tiny: https://huggingface.co/openai/whisper-tiny\n",
    "  - Small: https://huggingface.co/openai/whisper-small\n",
    "  - Medium: https://huggingface.co/openai/whisper-medium\n",
    "  - Large-v3: https://huggingface.co/openai/whisper-large-v3\n",
    "\n",
    "Given the largest model has only 1.5B params, it fits into just 1 core when quantized to bf16. Also, this model is an encoder-decoder, so the strategy is to compile both components individually and then put them back into the original model structure. After that, both encoder and decoder will be accelerated on inf2.\n",
    "\n",
    "You can use the smallest instance for this experiment: inf2.xlarge, but to achieve a higher througput by launching multiple copies of the model to serve clients in parallel, it is recommended to use a larger instance like ml.inf2.24xlarge or trn1.32xlarge.\n",
    "\n",
    "Follow the [instructions from this page to setup the environment.](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/setup/torch-neuronx.html#setup-torch-neuronx) It is recommended the usage of the following container (DLC) to run your experiments: **Deep Learning Container**: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-neuronx:1.13.1-neuronx-py310-sdk2.19.1-ubuntu20.04\n",
    "\n",
    "This guarantees you'll be using the exact same libraries of this experimentation.\n",
    "\n",
    "Also, make sure you install the following additional libraries in your environment. Pay attention to the transformers version, newer versions might not work.\n",
    "\n",
    "## Install Dependencies\n",
    "This tutorial requires the following pip packages:\n",
    "\n",
    "- `transformers==4.36.2`\n",
    "- `soundfile==0.12.1`\n",
    "- `datasets==2.18.0`\n",
    "- `librosa==0.10.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c7a7d7-ed9f-4a0d-bc49-246bb6b8f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa72f2bb-69b1-4753-ac3c-0ad84a068860",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export NEURON_RT_NUM_CORES='2'\n",
    "!export NEURON_RT_VISIBLE_CORES='0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2beede5-4669-4aa7-a0bd-98d81823a711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "WARNING:root:MASTER_ADDR environment variable is not set, defaulting to localhost\n",
      "WARNING:root:Found libneuronpjrt.so. Setting PJRT_DEVICE=NEURON.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of WhisperForConditionalGeneration were not initialized from the model checkpoint at openai/whisper-large-v3 and are newly initialized: ['proj_out.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of WhisperForConditionalGeneration were not initialized from the model checkpoint at openai/whisper-large-v3 and are newly initialized: ['proj_out.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of WhisperForConditionalGeneration were not initialized from the model checkpoint at openai/whisper-large-v3 and are newly initialized: ['proj_out.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim enc: 128; Dim dec: 1280\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['NEURON_RT_NUM_CORES']= \"2\"\n",
    "os.environ[\"NEURON_RT_VISIBLE_CORES\"] = \"0,1\"  # 使用するコア番号\n",
    "import types\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# please, start by selecting the desired model size\n",
    "#suffix=\"tiny\"\n",
    "#suffix=\"small\"\n",
    "#suffix=\"medium\"\n",
    "suffix=\"large-v3\"\n",
    "model_id=f\"openai/whisper-{suffix}\"\n",
    "\n",
    "# this will load the tokenizer + two copies of the model. cpu_model will be used later for results comparison\n",
    "processor = WhisperProcessor.from_pretrained(model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_id, torchscript=True)\n",
    "processor_2 = WhisperProcessor.from_pretrained(model_id)\n",
    "model_2 = WhisperForConditionalGeneration.from_pretrained(model_id, torchscript=True)\n",
    "cpu_model = WhisperForConditionalGeneration.from_pretrained(model_id, torchscript=True)\n",
    "\n",
    "# Load a sample from the dataset\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "# sample #3 is ~9.9seconds and produces 33 output tokens + pad token\n",
    "sample = dataset[3][\"audio\"]\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "\n",
    "# output_attentions is required if you want to return word timestamps\n",
    "# if you don't need timestamps, just set this to False and get some better latency\n",
    "output_attentions = True\n",
    "\n",
    "batch_size = 1\n",
    "# this is the maximum number of tokens the model will be able to decode\n",
    "# for the sample #3 we selected above, this is enough. If you're planning to \n",
    "# process larger samples, you need to adjust it accordinly.\n",
    "max_dec_len = 128\n",
    "# num_mel_bins,d_model --> these parameters where copied from model.conf (found on HF repo)\n",
    "# we need them to correctly generate dummy inputs during compilation\n",
    "dim_enc = model.config.num_mel_bins\n",
    "dim_dec = model.config.d_model\n",
    "print(f'Dim enc: {dim_enc}; Dim dec: {dim_dec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dab20e6-d8e6-44d2-ab0f-5bb041c9d7c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim enc: 128; Dim dec: 1280\n"
     ]
    }
   ],
   "source": [
    "# inference.py での動作確認用のセル\n",
    "import os\n",
    "os.environ['NEURON_RT_NUM_CORES']='1'\n",
    "import types\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig\n",
    "\n",
    "# please, start by selecting the desired model size\n",
    "#suffix=\"tiny\"\n",
    "#suffix=\"small\"\n",
    "#suffix=\"medium\"\n",
    "suffix=\"large-v3\"\n",
    "model_id=f\"openai/whisper-{suffix}\"\n",
    "\n",
    "# this will load the tokenizer + two copies of the model. cpu_model will be used later for results comparison\n",
    "processor = WhisperProcessor.from_pretrained(model_id)\n",
    "config = WhisperConfig.from_pretrained(model_id)\n",
    "model = WhisperForConditionalGeneration(config)\n",
    "\n",
    "max_dec_len = 128\n",
    "\n",
    "# Load a sample from the dataset\n",
    "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "# sample #3 is ~9.9seconds and produces 33 output tokens + pad token\n",
    "sample = dataset[3][\"audio\"]\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "\n",
    "output_attentions = True\n",
    "\n",
    "batch_size = 1\n",
    "# this is the maximum number of tokens the model will be able to decode\n",
    "# for the sample #3 we selected above, this is enough. If you're planning to \n",
    "# process larger samples, you need to adjust it accordinly.\n",
    "max_dec_len = 128\n",
    "# num_mel_bins,d_model --> these parameters where copied from model.conf (found on HF repo)\n",
    "# we need them to correctly generate dummy inputs during compilation\n",
    "dim_enc = model.config.num_mel_bins\n",
    "dim_dec = model.config.d_model\n",
    "print(f'Dim enc: {dim_enc}; Dim dec: {dim_dec}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27073a8f-6efd-49a6-a857-386762add8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import torch.nn.functional as F\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions,BaseModelOutput\n",
    "\n",
    "# Now we need to simplify both encoding & decoding forward methods to make them \n",
    "# compilable. Please notice that these methods overwrite the original ones, but\n",
    "# keeps retro-compatibility. Also, we'll use use a new variable \"forward_neuron\"\n",
    "# to invoke the model on inf2\n",
    "def enc_f(self, input_features, attention_mask, **kwargs):\n",
    "    if hasattr(self, 'forward_neuron'):\n",
    "        out = self.forward_neuron(input_features, attention_mask)\n",
    "    else:\n",
    "        out = self.forward_(input_features, attention_mask, return_dict=True)\n",
    "    return BaseModelOutput(**out)\n",
    "\n",
    "def dec_f(self, input_ids, attention_mask=None, encoder_hidden_states=None, **kwargs):\n",
    "    output = None        \n",
    "    if not attention_mask is None and encoder_hidden_states is None:\n",
    "        # this is a workaround to align the input parameters for NeuronSDK tracer\n",
    "        # None values are not allowed during compilation\n",
    "        encoder_hidden_states, attention_mask = attention_mask,encoder_hidden_states\n",
    "    inputs = [input_ids, encoder_hidden_states]\n",
    "    \n",
    "    # pad the input to max_dec_len\n",
    "    if inputs[0].shape[1] > self.max_length:\n",
    "        raise Exception(f\"The decoded sequence is not supported. Max: {self.max_length}\")\n",
    "    pad_size = torch.as_tensor(self.max_length - inputs[0].shape[1])\n",
    "    inputs[0] = F.pad(inputs[0], (0, pad_size), \"constant\", processor.tokenizer.pad_token_id)\n",
    "    \n",
    "    if hasattr(self, 'forward_neuron'):\n",
    "        output = self.forward_neuron(*inputs)\n",
    "    else:\n",
    "        # output_attentions is required if you want timestamps\n",
    "        output = self.forward_(input_ids=inputs[0], encoder_hidden_states=inputs[1], return_dict=True, use_cache=False, output_attentions=output_attentions)\n",
    "    # unpad the output\n",
    "    output['last_hidden_state'] = output['last_hidden_state'][:, :input_ids.shape[1], :]\n",
    "    # neuron compiler doesn't like tuples as values of dicts, so we stack them into tensors\n",
    "    # also, we need to average axis=2 given we're not using cache (use_cache=False)\n",
    "    # that way, to avoid an issue with the pipeline we change the shape from:\n",
    "    #  bs,num selected,num_tokens,1500 --> bs,1,num_tokens,1500\n",
    "    # I suspect there is a bug in the HF pipeline code that doesn't support use_cache=False for\n",
    "    # word timestamps, that's why we need that.\n",
    "    if not output.get('attentions') is None:\n",
    "        output['attentions'] = torch.stack([torch.mean(o[:, :, :input_ids.shape[1], :input_ids.shape[1]], axis=2, keepdim=True) for o in output['attentions']])\n",
    "    if not output.get('cross_attentions') is None:\n",
    "        output['cross_attentions'] = torch.stack([torch.mean(o[:, :, :input_ids.shape[1], :], axis=2, keepdim=True) for o in output['cross_attentions']])\n",
    "    return BaseModelOutputWithPastAndCrossAttentions(**output)\n",
    "\n",
    "def proj_out_f(self, inp):\n",
    "    pad_size = torch.as_tensor(self.max_length - inp.shape[1], device=inp.device)\n",
    "    # pad the input to max_dec_len\n",
    "    if inp.shape[1] > self.max_length:\n",
    "        raise Exception(f\"The decoded sequence is not supported. Max: {self.max_length}\")\n",
    "    x = F.pad(inp, (0,0,0,pad_size), \"constant\", processor.tokenizer.pad_token_id)\n",
    "    \n",
    "    if hasattr(self, 'forward_neuron'):\n",
    "        out = self.forward_neuron(x)\n",
    "    else:\n",
    "        out = self.forward_(x)\n",
    "    # unpad the output before returning\n",
    "    out = out[:, :inp.shape[1], :]\n",
    "    return out\n",
    "    \n",
    "if not hasattr(model.model.encoder, 'forward_'): model.model.encoder.forward_ = model.model.encoder.forward\n",
    "if not hasattr(model.model.decoder, 'forward_'): model.model.decoder.forward_ = model.model.decoder.forward\n",
    "if not hasattr(model.proj_out, 'forward_'): model.proj_out.forward_ = model.proj_out.forward\n",
    "\n",
    "model.model.encoder.forward = types.MethodType(enc_f, model.model.encoder)\n",
    "model.model.decoder.forward = types.MethodType(dec_f, model.model.decoder)\n",
    "model.proj_out.forward = types.MethodType(proj_out_f, model.proj_out)\n",
    "\n",
    "model.model.decoder.max_length = max_dec_len\n",
    "model.proj_out.max_length = max_dec_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac233086-8371-4090-bcaf-af9f4382adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(model_2.model.encoder, 'forward_'): model_2.model.encoder.forward_ = model_2.model.encoder.forward\n",
    "if not hasattr(model_2.model.decoder, 'forward_'): model_2.model.decoder.forward_ = model_2.model.decoder.forward\n",
    "if not hasattr(model_2.proj_out, 'forward_'): model_2.proj_out.forward_ = model_2.proj_out.forward\n",
    "\n",
    "model_2.model.encoder.forward = types.MethodType(enc_f, model_2.model.encoder)\n",
    "model_2.model.decoder.forward = types.MethodType(dec_f, model_2.model.decoder)\n",
    "model_2.proj_out.forward = types.MethodType(proj_out_f, model_2.proj_out)\n",
    "\n",
    "model_2.model.decoder.max_length = max_dec_len\n",
    "model_2.proj_out.max_length = max_dec_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd76350-916d-4747-8482-89636940ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WhisperModel is using WhisperSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `layer_head_mask` not None. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    }
   ],
   "source": [
    "# warmup model\n",
    "y1 = model.generate(input_features)\n",
    "# y2 = model_2.generate(input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346a219-4e02-40f9-8a57-a7c8752aab30",
   "metadata": {},
   "source": [
    "## Trace Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e226771-085c-46eb-9ead-e13849b3c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "658f3365-2190-42e1-b5bf-aa8919a16ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b42dd54-a640-4903-8ce6-72f19d20ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写経\n",
    "import os\n",
    "import torch\n",
    "import torch_neuronx\n",
    "\n",
    "model_filename = f\"neuron_model/whisper_{suffix}_{batch_size}_neuron_encoder.pt\"\n",
    "\n",
    "if not os.path.isfile(model_filename):\n",
    "    inputs = (\n",
    "        torch.zeros([1, dim_enc, 3000],dtype=torch.float32),\n",
    "        torch.zeros([1, dim_enc], dtype=torch.int64))\n",
    "    if hasattr(model.model.encoder, \"forward_neuron\"): del model.model.encoder.forward_neuron\n",
    "    neuron_encoder = torch_neuronx.trace(\n",
    "        model.model.encoder,\n",
    "        inputs,\n",
    "        compiler_args=\"--model-type=transformer --auto-cast=all --auto-cast-type=bf16\",\n",
    "        compiler_workdir=\"./enc_dir\",\n",
    "        inline_weights_to_neff=False)\n",
    "    neuron_encoder.save(model_filename)\n",
    "    model.model.encoder.forward_neuron = neuron_encoder\n",
    "else:\n",
    "    with torch_neuronx.experimental.neuron_cores_context(start_nc=0, nc_count=1):\n",
    "        model_2.model.encoder.forward_neuron = torch.jit.load(model_filename)\n",
    "    # model.model.encoder.forward_neuron = torch_neuronx.DataParallel(torch.jit.load(model_filename), device_ids, set_dynamic_batching=False)\n",
    "with torch_neuronx.experimental.neuron_cores_context(start_nc=1, nc_count=1):\n",
    "    model_2.model.encoder.forward_neuron = torch.jit.load(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a8e74-7971-4f8e-b60a-84aed9bdd186",
   "metadata": {},
   "source": [
    "## Trace decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ea4f30-f1a2-47f6-9583-1eb7d26ae882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuronx\n",
    "\n",
    "model_filename=f\"neuron_model/whisper_{suffix}_{batch_size}_{max_dec_len}_neuron_decoder.pt\"\n",
    "# モデル1にNeuron Core 0-1を割り当て\n",
    "\n",
    "if not os.path.isfile(model_filename):\n",
    "    inputs = (torch.zeros([1, max_dec_len], dtype=torch.int64), torch.zeros([1, 1500, dim_dec], dtype=torch.float32))\n",
    "    if hasattr(model.model.decoder, 'forward_neuron'): del model.model.decoder.forward_neuron\n",
    "    neuron_decoder = torch_neuronx.trace(\n",
    "        model.model.decoder, \n",
    "        inputs,\n",
    "        compiler_args='--model-type=transformer --auto-cast=all --auto-cast-type=bf16',\n",
    "        compiler_workdir='./dec_dir',      \n",
    "        inline_weights_to_neff=True)\n",
    "    neuron_decoder.save(model_filename)\n",
    "    model.model.decoder.forward_neuron = neuron_decoder\n",
    "else:\n",
    "    with torch_neuronx.experimental.neuron_cores_context(start_nc=0, nc_count=1):\n",
    "        # model.model.decoder.forward_neuron = torch_neuronx.DataParallel(torch.jit.load(model_filename), device_ids, set_dynamic_batching=False)\n",
    "        model.model.decoder.forward_neuron = torch.jit.load(model_filename)\n",
    "with torch_neuronx.experimental.neuron_cores_context(start_nc=1, nc_count=1):\n",
    "    model_2.model.decoder.forward_neuron = torch.jit.load(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333dcfb-0311-49e6-92b9-31485727f3c5",
   "metadata": {},
   "source": [
    "## Trace Projection Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59190d0-f03d-494d-a187-e6891d5a7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuronx\n",
    "\n",
    "model_filename=f\"neuron_model/whisper_{suffix}_{batch_size}_{max_dec_len}_neuron_proj.pt\"\n",
    "if not os.path.isfile(model_filename):\n",
    "    inputs = torch.zeros([1, max_dec_len, dim_dec], dtype=torch.float32)\n",
    "    if hasattr(model.proj_out, 'forward_neuron'): del model.proj_out.forward_neuron\n",
    "    neuron_decoder = torch_neuronx.trace(\n",
    "        model.proj_out, \n",
    "        inputs,\n",
    "        compiler_args='--model-type=transformer --auto-cast=all --auto-cast-type=bf16',\n",
    "        compiler_workdir='./proj_out_dir',      \n",
    "        inline_weights_to_neff=True)\n",
    "    neuron_decoder.save(model_filename)\n",
    "    model.proj_out.forward_neuron = neuron_decoder\n",
    "else:\n",
    "    # model.proj_out.forward_neuron = torch_neuronx.DataParallel(torch.jit.load(model_filename), device_ids, set_dynamic_batching=False)\n",
    "    with torch_neuronx.experimental.neuron_cores_context(start_nc=0, nc_count=1):\n",
    "        model.proj_out.forward_neuron = torch.jit.load(model_filename)\n",
    "with torch_neuronx.experimental.neuron_cores_context(start_nc=1, nc_count=1):\n",
    "    model_2.proj_out.forward_neuron = torch.jit.load(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aca1ee-7419-4e20-abb4-d0d7ae5093b5",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "246d6ad3-e788-474b-8b21-31feea10872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup inf2 model\n",
    "y1 = model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b016563-3025-48c9-81b4-570fd6a8fa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50360, 50364,   634,   575, 12525, 22618,  1968,  6144,\n",
       "         35617,  1456,   397,   266,   311,   589,   307,   534, 10281,   934,\n",
       "           439,    11,   293,   393,  4411,   294,   309,   457,   707,   295,\n",
       "         33301,   286,   392,  6628,    13, 50257]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9c6653-6ce3-4429-a0ea-6c641cabc265",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f14bc1-fb93-435a-b171-002287c68d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed inf2: 8.855262994766235\n",
      "Elapsed cpu: 17.03957748413086\n",
      "Tokens inf2: tensor([[50258, 50259, 50360, 50364,   634,   575, 12525, 22618,  1968,  6144,\n",
      "         35617,  1456,   397,   266,   311,   589,   307,   534, 10281,   934,\n",
      "           439,    11,   293,   393,  4411,   294,   309,   457,   707,   295,\n",
      "         33301,   286,   392,  6628,    13, 50257]])\n",
      "Tokens cpu: tensor([[50258, 50259, 50360, 50364,   634,   575, 12525, 22618,  1968,  6144,\n",
      "         35617,  1456,   397,   266,   311,   589,   307,   534, 10281,   934,\n",
      "           439,    11,   293,   393,  4411,   294,   309,   457,   707,   295,\n",
      "         33301,   286,   392,  6628,    13, 50257]])\n",
      "Out inf2: [\" He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca.\"]\n",
      "Out cpu: [\" He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca.\"]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "y1 = model.generate(input_features)\n",
    "print(f\"Elapsed inf2: {time.time()-t}\")\n",
    "t = time.time()\n",
    "y2 = cpu_model.generate(input_features)\n",
    "print(f\"Elapsed cpu: {time.time()-t}\")\n",
    "print(f\"Tokens inf2: {y1}\")\n",
    "print(f\"Tokens cpu: {y2}\")\n",
    "t1 = processor.batch_decode(y1, skip_special_tokens=True)\n",
    "t2 = processor.batch_decode(y2, skip_special_tokens=True)\n",
    "print(f\"Out inf2: {t1}\")\n",
    "print(f\"Out cpu: {t2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af72c44-1104-4464-8ae1-c3021dfe68cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pipeline Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a287752-fec2-4b4e-985e-253247fd5f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "/opt/aws_neuronx_venv_pytorch_2_5_transformers/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 7.2860918045043945\n",
      "{'text': ' He', 'timestamp': (0.0, 0.56)}\n",
      "{'text': ' has', 'timestamp': (0.56, 0.76)}\n",
      "{'text': ' grave', 'timestamp': (0.76, 1.06)}\n",
      "{'text': ' doubts', 'timestamp': (1.06, 1.42)}\n",
      "{'text': ' whether', 'timestamp': (1.42, 1.88)}\n",
      "{'text': ' Sir', 'timestamp': (1.88, 2.28)}\n",
      "{'text': ' Frederick', 'timestamp': (2.28, 2.62)}\n",
      "{'text': \" Leighton's\", 'timestamp': (2.62, 3.2)}\n",
      "{'text': ' work', 'timestamp': (3.2, 3.46)}\n",
      "{'text': ' is', 'timestamp': (3.46, 3.68)}\n",
      "{'text': ' really', 'timestamp': (3.68, 4.02)}\n",
      "{'text': ' Greek', 'timestamp': (4.02, 4.62)}\n",
      "{'text': ' after', 'timestamp': (4.62, 4.98)}\n",
      "{'text': ' all,', 'timestamp': (4.98, 5.5)}\n",
      "{'text': ' and', 'timestamp': (5.5, 6.16)}\n",
      "{'text': ' can', 'timestamp': (6.16, 6.32)}\n",
      "{'text': ' discover', 'timestamp': (6.32, 6.74)}\n",
      "{'text': ' in', 'timestamp': (6.74, 7.02)}\n",
      "{'text': ' it', 'timestamp': (7.02, 7.22)}\n",
      "{'text': ' but', 'timestamp': (7.22, 7.38)}\n",
      "{'text': ' little', 'timestamp': (7.38, 7.76)}\n",
      "{'text': ' of', 'timestamp': (7.76, 8.06)}\n",
      "{'text': ' rocky', 'timestamp': (8.06, 8.56)}\n",
      "{'text': ' Ithaca.', 'timestamp': (8.56, None)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "# import torch_neuronx\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, WhisperProcessor\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "cpu_pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=model_id,\n",
    "  chunk_length_s=30\n",
    ")\n",
    "# cpu_pipe.model = cpu_model\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = ds[3][\"audio\"]\n",
    "\n",
    "# we can also return timestamps for the predictions\n",
    "## Option return_timestamps can be: True, False, \"word\" or \"char\"\n",
    "t = time.time()\n",
    "prediction = cpu_pipe(sample.copy(), batch_size=1, return_timestamps=\"word\")[\"chunks\"]\n",
    "print(f\"Elapsed: {time.time()-t}\")\n",
    "for p in prediction:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49e7bf44-f05f-4f6c-ad0a-5af5d2c187a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 1.8384795188903809\n",
      "{'text': ' He', 'timestamp': (0.64, 0.64)}\n",
      "{'text': ' has', 'timestamp': (0.64, 0.76)}\n",
      "{'text': ' grave', 'timestamp': (0.76, 1.02)}\n",
      "{'text': ' doubts', 'timestamp': (1.02, 1.46)}\n",
      "{'text': ' whether', 'timestamp': (1.46, 1.78)}\n",
      "{'text': ' Sir', 'timestamp': (1.78, 2.22)}\n",
      "{'text': ' Frederick', 'timestamp': (2.22, 2.66)}\n",
      "{'text': \" Leighton's\", 'timestamp': (2.66, 3.1)}\n",
      "{'text': ' work', 'timestamp': (3.1, 3.44)}\n",
      "{'text': ' is', 'timestamp': (3.44, 3.7)}\n",
      "{'text': ' really', 'timestamp': (3.7, 4.06)}\n",
      "{'text': ' Greek', 'timestamp': (4.06, 4.68)}\n",
      "{'text': ' after', 'timestamp': (4.68, 4.94)}\n",
      "{'text': ' all,', 'timestamp': (4.94, 5.42)}\n",
      "{'text': ' and', 'timestamp': (5.42, 6.1)}\n",
      "{'text': ' can', 'timestamp': (6.1, 6.36)}\n",
      "{'text': ' discover', 'timestamp': (6.36, 6.76)}\n",
      "{'text': ' in', 'timestamp': (6.76, 7.0)}\n",
      "{'text': ' it', 'timestamp': (7.0, 7.22)}\n",
      "{'text': ' but', 'timestamp': (7.22, 7.4)}\n",
      "{'text': ' little', 'timestamp': (7.4, 7.82)}\n",
      "{'text': ' of', 'timestamp': (7.82, 8.12)}\n",
      "{'text': ' rocky', 'timestamp': (8.12, 8.72)}\n",
      "{'text': ' Ithaca.', 'timestamp': (8.72, 9.24)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_neuronx\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, WhisperProcessor\n",
    "\n",
    "if not output_attentions:\n",
    "    raise Exception(\"Word timestamp not supported. Please set output_attentions=True and recompile the model\")\n",
    "\n",
    "pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=model_id,\n",
    "  chunk_length_s=30\n",
    ")\n",
    "pipe.model = model\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = ds[3][\"audio\"]\n",
    "\n",
    "# we can also return timestamps for the predictions\n",
    "## Option return_timestamps can be: True, False, \"word\" or \"char\"\n",
    "t=time.time()\n",
    "prediction = pipe(sample.copy(), batch_size=1, return_timestamps=\"word\")[\"chunks\"]\n",
    "print(f\"Elapsed: {time.time()-t}\")\n",
    "for p in prediction:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e1600-53fc-49f6-a3a8-272928611e9d",
   "metadata": {},
   "source": [
    "## Performance benchmnark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58285f7-44b6-46ab-8a75-7d574ebc9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import time\n",
    "import concurrent.futures\n",
    "from typing import Dict, Any\n",
    "\n",
    "def process_with_model(sample: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"モデル1で音声処理を行う関数\"\"\"\n",
    "    input_features = processor(\n",
    "        sample[\"audio\"][\"array\"], \n",
    "        sampling_rate=sample[\"audio\"][\"sampling_rate\"], \n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "    \n",
    "    start_time = time.time()\n",
    "    generated = model.generate(input_features)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    transcription = processor.batch_decode(generated, skip_special_tokens=True)\n",
    "    print(\"Inference time: \", inference_time)\n",
    "    return {\n",
    "        \"model\": \"model_1\",\n",
    "        \"inference_time\": inference_time,\n",
    "        \"transcription\": transcription\n",
    "    }\n",
    "\n",
    "def process_with_model_2(sample: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"モデル2で音声処理を行う関数\"\"\"\n",
    "    input_features = processor_2(\n",
    "        sample[\"audio\"][\"array\"], \n",
    "        sampling_rate=sample[\"audio\"][\"sampling_rate\"], \n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features\n",
    "    \n",
    "    start_time = time.time()\n",
    "    generated = model_2.generate(input_features)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    transcription = processor_2.batch_decode(generated, skip_special_tokens=True)\n",
    "    print(\"Inference time: \", inference_time)\n",
    "    return {\n",
    "        \"model\": \"model_2\",\n",
    "        \"inference_time\": inference_time,\n",
    "        \"transcription\": transcription\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791fad08-b030-495a-94b2-58f8c1a46e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_inference():\n",
    "    total_start_time = time.time()\n",
    "    total_samples = 0\n",
    "    futures = []\n",
    "    try:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "            for sample in dataset_iter:\n",
    "                total_samples += 1\n",
    "                if total_samples % 2 == 0:\n",
    "                    # 結果を返すFutureオブジェクトを保存\n",
    "                    future = executor.submit(process_with_model, sample)\n",
    "                    futures.append(future)\n",
    "                else:\n",
    "                    future = executor.submit(process_with_model_2, sample)\n",
    "                    futures.append(future)\n",
    "            \n",
    "            # すべてのタスクが完了するまで待つ\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                try:\n",
    "                    # タスクの結果を取得（エラーがあれば例外が発生）\n",
    "                    result = future.result()\n",
    "                    # 必要に応じて結果を処理\n",
    "                    print(f\"Model: {result['model']}, Inference time: {result['inference_time']:.4f}s\")\n",
    "                    # print(f\"Transcription: {result['transcription']}\")\n",
    "                except Exception as exc:\n",
    "                    print(f\"Task generated an exception: {exc}\")            \n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "    total_time = time.time() - total_start_time\n",
    "    print(f\"Total processing time: {total_time:.4f}s\")\n",
    "    print(f\"Total samples processed: {total_samples}\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434d09bc-a6ef-4b00-8fb1-abce3fcc67b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06acaa315e664953963295119d74d5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('MLCommons/peoples_speech', \"microset\", split='train', streaming=True)\n",
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c254b1b-1963-4496-856f-bcedf04b23ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 μs, sys: 5 μs, total: 10 μs\n",
      "Wall time: 21.2 μs\n",
      "Inference time:  4.084258794784546\n",
      "Model: model_1, Inference time: 4.0843s\n",
      "Inference time:  4.208552598953247\n",
      "Model: model_2, Inference time: 4.2086s\n",
      "Inference time:  2.32397198677063\n",
      "Model: model_2, Inference time: 2.3240s\n",
      "Inference time:  2.65513277053833\n",
      "Model: model_1, Inference time: 2.6551s\n",
      "Inference time:  2.3822758197784424\n",
      "Model: model_2, Inference time: 2.3823s\n",
      "Inference time:  2.5961320400238037\n",
      "Model: model_1, Inference time: 2.5961s\n",
      "Inference time:  2.4981768131256104\n",
      "Model: model_2, Inference time: 2.4982s\n",
      "Inference time:  3.8852834701538086\n",
      "Model: model_1, Inference time: 3.8853s\n",
      "Inference time:  2.8445322513580322\n",
      "Model: model_2, Inference time: 2.8445s\n",
      "Inference time:  2.201923370361328\n",
      "Model: model_2, Inference time: 2.2019s\n",
      "Inference time:  10.19257640838623\n",
      "Model: model_1, Inference time: 10.1926s\n",
      "Inference time:  7.156795978546143\n",
      "Model: model_1, Inference time: 7.1568s\n",
      "Inference time:  2.614192008972168\n",
      "Model: model_2, Inference time: 2.6142s\n",
      "Inference time:  2.3760499954223633\n",
      "Model: model_2, Inference time: 2.3760s\n",
      "Inference time:  9.8557448387146\n",
      "Model: model_1, Inference time: 9.8557s\n",
      "Inference time:  15.315576314926147\n",
      "Model: model_1, Inference time: 15.3156s\n",
      "Inference time:  2.514472007751465\n",
      "Model: model_2, Inference time: 2.5145s\n",
      "Inference time:  3.3576297760009766\n",
      "Model: model_1, Inference time: 3.3576s\n",
      "Inference time:  2.1399881839752197\n",
      "Model: model_2, Inference time: 2.1400s\n",
      "Inference time:  1.9405817985534668\n",
      "Model: model_2, Inference time: 1.9406s\n",
      "Inference time:  3.125326633453369\n",
      "Model: model_1, Inference time: 3.1253s\n",
      "Inference time:  2.2698051929473877\n",
      "Model: model_2, Inference time: 2.2698s\n",
      "Inference time:  3.212341070175171\n",
      "Model: model_1, Inference time: 3.2123s\n",
      "Inference time:  2.0730435848236084\n",
      "Model: model_2, Inference time: 2.0730s\n",
      "Inference time:  3.649566411972046\n",
      "Model: model_1, Inference time: 3.6496s\n",
      "Inference time:  1.6669282913208008\n",
      "Model: model_2, Inference time: 1.6669s\n",
      "Inference time:  3.1456785202026367\n",
      "Model: model_1, Inference time: 3.1457s\n",
      "Inference time:  2.4489595890045166\n",
      "Model: model_2, Inference time: 2.4490s\n",
      "Inference time:  3.182751178741455\n",
      "Model: model_1, Inference time: 3.1828s\n",
      "Inference time:  1.985222578048706\n",
      "Model: model_2, Inference time: 1.9852s\n",
      "Inference time:  2.9379189014434814\n",
      "Model: model_1, Inference time: 2.9379s\n",
      "Inference time:  1.3022527694702148\n",
      "Model: model_2, Inference time: 1.3023s\n",
      "Inference time:  3.192448377609253\n",
      "Model: model_1, Inference time: 3.1924s\n",
      "Inference time:  2.8807599544525146\n",
      "Model: model_1, Inference time: 2.8808s\n",
      "Inference time:  1.934556484222412\n",
      "Model: model_2, Inference time: 1.9346s\n",
      "Inference time:  2.4857540130615234\n",
      "Model: model_2, Inference time: 2.4858s\n",
      "Inference time:  3.5527334213256836\n",
      "Model: model_1, Inference time: 3.5527s\n",
      "Inference time:  2.598395824432373\n",
      "Model: model_2, Inference time: 2.5984s\n",
      "Inference time:  3.5022480487823486\n",
      "Model: model_1, Inference time: 3.5022s\n",
      "Inference time:  2.088639736175537\n",
      "Model: model_2, Inference time: 2.0886s\n",
      "Inference time:  3.0225071907043457\n",
      "Model: model_1, Inference time: 3.0225s\n",
      "Inference time:  3.044053316116333\n",
      "Model: model_1, Inference time: 3.0441s\n",
      "Inference time:  2.539051055908203\n",
      "Model: model_2, Inference time: 2.5391s\n",
      "Inference time:  2.9908504486083984\n",
      "Model: model_1, Inference time: 2.9909s\n",
      "Inference time:  2.7313449382781982\n",
      "Model: model_2, Inference time: 2.7313s\n",
      "Inference time:  2.593991994857788\n",
      "Model: model_2, Inference time: 2.5940s\n",
      "Inference time:  3.6656713485717773\n",
      "Model: model_1, Inference time: 3.6657s\n",
      "Inference time:  3.0838489532470703\n",
      "Model: model_1, Inference time: 3.0838s\n",
      "Inference time:  2.329899549484253\n",
      "Model: model_2, Inference time: 2.3299s\n",
      "Inference time:  2.546248435974121\n",
      "Model: model_2, Inference time: 2.5462s\n",
      "Inference time:  2.818486452102661\n",
      "Model: model_1, Inference time: 2.8185s\n",
      "Inference time:  2.447730779647827\n",
      "Model: model_2, Inference time: 2.4477s\n",
      "Inference time:  3.4103682041168213\n",
      "Model: model_1, Inference time: 3.4104s\n",
      "Inference time:  2.1001577377319336\n",
      "Model: model_2, Inference time: 2.1002s\n",
      "Inference time:  3.155064344406128\n",
      "Model: model_1, Inference time: 3.1551s\n",
      "Inference time:  2.1039962768554688\n",
      "Model: model_2, Inference time: 2.1040s\n",
      "Inference time:  4.249083042144775\n",
      "Model: model_1, Inference time: 4.2491s\n",
      "Inference time:  3.3038318157196045\n",
      "Model: model_1, Inference time: 3.3038s\n",
      "Inference time:  2.480196952819824\n",
      "Model: model_2, Inference time: 2.4802s\n",
      "Inference time:  1.508378028869629\n",
      "Model: model_2, Inference time: 1.5084s\n",
      "Inference time:  4.132853746414185\n",
      "Model: model_1, Inference time: 4.1329s\n",
      "Inference time:  2.7816286087036133\n",
      "Model: model_1, Inference time: 2.7816s\n",
      "Inference time:  4.026963710784912\n",
      "Model: model_2, Inference time: 4.0270s\n",
      "Inference time:  1.805727481842041\n",
      "Model: model_2, Inference time: 1.8057s\n",
      "Inference time:  3.0490880012512207\n",
      "Model: model_1, Inference time: 3.0491s\n",
      "Inference time:  2.206085443496704\n",
      "Model: model_2, Inference time: 2.2061s\n",
      "Inference time:  2.796668767929077\n",
      "Model: model_1, Inference time: 2.7967s\n",
      "Inference time:  2.047705888748169\n",
      "Model: model_2, Inference time: 2.0477s\n",
      "Inference time:  2.619138479232788\n",
      "Model: model_1, Inference time: 2.6191s\n",
      "Inference time:  2.0642597675323486\n",
      "Model: model_2, Inference time: 2.0643s\n",
      "Inference time:  3.5205976963043213\n",
      "Model: model_1, Inference time: 3.5206s\n",
      "Inference time:  2.878129005432129\n",
      "Model: model_1, Inference time: 2.8781s\n",
      "Inference time:  2.6265554428100586\n",
      "Model: model_2, Inference time: 2.6266s\n",
      "Inference time:  3.758734703063965\n",
      "Model: model_1, Inference time: 3.7587s\n",
      "Inference time:  3.00003981590271\n",
      "Model: model_2, Inference time: 3.0000s\n",
      "Inference time:  2.1441423892974854\n",
      "Model: model_2, Inference time: 2.1441s\n",
      "Inference time:  2.9690299034118652\n",
      "Model: model_1, Inference time: 2.9690s\n",
      "Inference time:  1.8116436004638672\n",
      "Model: model_2, Inference time: 1.8116s\n",
      "Inference time:  2.5452046394348145\n",
      "Model: model_1, Inference time: 2.5452s\n",
      "Inference time:  2.9443318843841553\n",
      "Model: model_1, Inference time: 2.9443s\n",
      "Inference time:  2.8734683990478516\n",
      "Model: model_2, Inference time: 2.8735s\n",
      "Inference time:  1.817467212677002\n",
      "Model: model_2, Inference time: 1.8175s\n",
      "Inference time:  3.4883952140808105\n",
      "Model: model_1, Inference time: 3.4884s\n",
      "Inference time:  2.6962149143218994\n",
      "Model: model_1, Inference time: 2.6962s\n",
      "Inference time:  1.9752075672149658\n",
      "Model: model_2, Inference time: 1.9752s\n",
      "Inference time:  2.2739601135253906\n",
      "Model: model_2, Inference time: 2.2740s\n",
      "Inference time:  3.4169578552246094\n",
      "Model: model_1, Inference time: 3.4170s\n",
      "Inference time:  2.2889997959136963\n",
      "Model: model_2, Inference time: 2.2890s\n",
      "Inference time:  3.2191076278686523\n",
      "Model: model_1, Inference time: 3.2191s\n",
      "Inference time:  2.701922655105591\n",
      "Model: model_1, Inference time: 2.7019s\n",
      "Inference time:  2.670764207839966\n",
      "Model: model_2, Inference time: 2.6708s\n",
      "Inference time:  1.9393258094787598\n",
      "Model: model_2, Inference time: 1.9393s\n",
      "Inference time:  3.2461397647857666\n",
      "Model: model_1, Inference time: 3.2461s\n",
      "Inference time:  2.213855028152466\n",
      "Model: model_2, Inference time: 2.2139s\n",
      "Inference time:  3.309074878692627\n",
      "Model: model_1, Inference time: 3.3091s\n",
      "Inference time:  2.061702013015747\n",
      "Model: model_2, Inference time: 2.0617s\n",
      "Inference time:  3.138030529022217\n",
      "Model: model_1, Inference time: 3.1380s\n",
      "Inference time:  2.271108865737915\n",
      "Model: model_2, Inference time: 2.2711s\n",
      "Inference time:  3.0587780475616455\n",
      "Model: model_1, Inference time: 3.0588s\n",
      "Inference time:  2.0343832969665527\n",
      "Model: model_2, Inference time: 2.0344s\n",
      "Inference time:  3.062300682067871\n",
      "Model: model_1, Inference time: 3.0623s\n",
      "Inference time:  2.812894344329834\n",
      "Model: model_1, Inference time: 2.8129s\n",
      "Inference time:  2.4508843421936035\n",
      "Model: model_2, Inference time: 2.4509s\n",
      "Inference time:  1.6488564014434814\n",
      "Model: model_2, Inference time: 1.6489s\n",
      "Inference time:  4.119194507598877\n",
      "Model: model_1, Inference time: 4.1192s\n",
      "Inference time:  3.192028045654297\n",
      "Model: model_1, Inference time: 3.1920s\n",
      "Inference time:  2.129692316055298\n",
      "Model: model_2, Inference time: 2.1297s\n",
      "Inference time:  2.043146848678589\n",
      "Model: model_2, Inference time: 2.0431s\n",
      "Inference time:  4.0417540073394775\n",
      "Model: model_1, Inference time: 4.0418s\n",
      "Inference time:  2.022240400314331\n",
      "Model: model_2, Inference time: 2.0222s\n",
      "Inference time:  4.026404619216919\n",
      "Model: model_1, Inference time: 4.0264s\n",
      "Inference time:  2.491811752319336\n",
      "Model: model_2, Inference time: 2.4918s\n",
      "Inference time:  3.432379961013794\n",
      "Model: model_1, Inference time: 3.4324s\n",
      "Inference time:  2.189358949661255\n",
      "Model: model_2, Inference time: 2.1894s\n",
      "Inference time:  3.5017004013061523\n",
      "Model: model_1, Inference time: 3.5017s\n",
      "Inference time:  2.533271551132202\n",
      "Model: model_2, Inference time: 2.5333s\n",
      "Inference time:  4.041699171066284\n",
      "Model: model_1, Inference time: 4.0417s\n",
      "Inference time:  2.3359076976776123\n",
      "Model: model_2, Inference time: 2.3359s\n",
      "Inference time:  4.0083441734313965\n",
      "Model: model_1, Inference time: 4.0083s\n",
      "Inference time:  2.159564256668091\n",
      "Model: model_2, Inference time: 2.1596s\n",
      "Inference time:  4.095143795013428\n",
      "Model: model_1, Inference time: 4.0951s\n",
      "Inference time:  1.91426682472229\n",
      "Model: model_2, Inference time: 1.9143s\n",
      "Inference time:  4.052498817443848\n",
      "Model: model_1, Inference time: 4.0525s\n",
      "Inference time:  0.8270602226257324\n",
      "Model: model_2, Inference time: 0.8271s\n",
      "Inference time:  2.6558837890625\n",
      "Model: model_1, Inference time: 2.6559s\n",
      "Inference time:  1.7928884029388428\n",
      "Model: model_2, Inference time: 1.7929s\n",
      "Inference time:  2.7118327617645264\n",
      "Model: model_1, Inference time: 2.7118s\n",
      "Inference time:  2.1790895462036133\n",
      "Model: model_2, Inference time: 2.1791s\n",
      "Inference time:  3.7818663120269775\n",
      "Model: model_1, Inference time: 3.7819s\n",
      "Inference time:  1.9729723930358887\n",
      "Model: model_2, Inference time: 1.9730s\n",
      "Inference time:  3.089959144592285\n",
      "Model: model_1, Inference time: 3.0900s\n",
      "Inference time:  2.1447901725769043\n",
      "Model: model_2, Inference time: 2.1448s\n",
      "Inference time:  3.115678310394287\n",
      "Model: model_1, Inference time: 3.1157s\n",
      "Inference time:  1.890509843826294\n",
      "Model: model_1, Inference time: 1.8905s\n",
      "Inference time:  2.3035049438476562\n",
      "Model: model_2, Inference time: 2.3035s\n",
      "Inference time:  0.7269375324249268\n",
      "Model: model_2, Inference time: 0.7269s\n",
      "Inference time:  3.5343170166015625\n",
      "Model: model_1, Inference time: 3.5343s\n",
      "Inference time:  2.5873258113861084\n",
      "Model: model_1, Inference time: 2.5873s\n",
      "Inference time:  1.8138165473937988\n",
      "Model: model_2, Inference time: 1.8138s\n",
      "Inference time:  3.190868377685547\n",
      "Model: model_1, Inference time: 3.1909s\n",
      "Inference time:  2.384890079498291\n",
      "Model: model_2, Inference time: 2.3849s\n",
      "Inference time:  2.083662986755371\n",
      "Model: model_2, Inference time: 2.0837s\n",
      "Inference time:  3.2380096912384033\n",
      "Model: model_1, Inference time: 3.2380s\n",
      "Inference time:  3.309237480163574\n",
      "Model: model_1, Inference time: 3.3092s\n",
      "Inference time:  2.406006097793579\n",
      "Model: model_2, Inference time: 2.4060s\n",
      "Inference time:  1.9409003257751465\n",
      "Model: model_2, Inference time: 1.9409s\n",
      "Inference time:  2.9983296394348145\n",
      "Model: model_1, Inference time: 2.9983s\n",
      "Inference time:  3.265669584274292\n",
      "Model: model_1, Inference time: 3.2657s\n",
      "Inference time:  2.696725845336914\n",
      "Model: model_2, Inference time: 2.6967s\n",
      "Inference time:  1.532515525817871\n",
      "Model: model_2, Inference time: 1.5325s\n",
      "Inference time:  3.0193710327148438\n",
      "Model: model_1, Inference time: 3.0194s\n",
      "Inference time:  2.7088639736175537\n",
      "Model: model_1, Inference time: 2.7089s\n",
      "Inference time:  1.7610132694244385\n",
      "Model: model_2, Inference time: 1.7610s\n",
      "Inference time:  2.1814684867858887\n",
      "Model: model_2, Inference time: 2.1815s\n",
      "Inference time:  2.8761472702026367\n",
      "Model: model_1, Inference time: 2.8761s\n",
      "Inference time:  2.4688191413879395\n",
      "Model: model_2, Inference time: 2.4688s\n",
      "Inference time:  3.543307065963745\n",
      "Model: model_1, Inference time: 3.5433s\n",
      "Inference time:  2.268479585647583\n",
      "Model: model_2, Inference time: 2.2685s\n",
      "Inference time:  3.9187519550323486\n",
      "Model: model_1, Inference time: 3.9188s\n",
      "Inference time:  2.9421091079711914\n",
      "Model: model_1, Inference time: 2.9421s\n",
      "Inference time:  2.7468252182006836\n",
      "Model: model_2, Inference time: 2.7468s\n",
      "Inference time:  1.990260362625122\n",
      "Model: model_2, Inference time: 1.9903s\n",
      "Inference time:  3.053682327270508\n",
      "Model: model_1, Inference time: 3.0537s\n",
      "Inference time:  2.406132221221924\n",
      "Model: model_2, Inference time: 2.4061s\n",
      "Inference time:  3.458890438079834\n",
      "Model: model_1, Inference time: 3.4589s\n",
      "Inference time:  2.057206392288208\n",
      "Model: model_2, Inference time: 2.0572s\n",
      "Inference time:  3.7672386169433594\n",
      "Model: model_1, Inference time: 3.7672s\n",
      "Inference time:  3.3743152618408203\n",
      "Model: model_1, Inference time: 3.3743s\n",
      "Inference time:  2.4594767093658447\n",
      "Model: model_2, Inference time: 2.4595s\n",
      "Inference time:  1.9061741828918457\n",
      "Model: model_2, Inference time: 1.9062s\n",
      "Inference time:  3.021111488342285\n",
      "Model: model_1, Inference time: 3.0211s\n",
      "Inference time:  2.9063141345977783\n",
      "Model: model_1, Inference time: 2.9063s\n",
      "Inference time:  2.553670883178711\n",
      "Model: model_2, Inference time: 2.5537s\n",
      "Inference time:  1.5771632194519043\n",
      "Model: model_2, Inference time: 1.5772s\n",
      "Inference time:  3.598045825958252\n",
      "Model: model_1, Inference time: 3.5980s\n",
      "Inference time:  1.7328076362609863\n",
      "Model: model_2, Inference time: 1.7328s\n",
      "Inference time:  3.454059362411499\n",
      "Model: model_1, Inference time: 3.4541s\n",
      "Inference time:  1.2990081310272217\n",
      "Model: model_2, Inference time: 1.2990s\n",
      "Inference time:  3.149660348892212\n",
      "Model: model_1, Inference time: 3.1497s\n",
      "Inference time:  2.9316413402557373\n",
      "Model: model_1, Inference time: 2.9316s\n",
      "Inference time:  2.1552553176879883\n",
      "Model: model_2, Inference time: 2.1553s\n",
      "Inference time:  1.8302690982818604\n",
      "Model: model_2, Inference time: 1.8303s\n",
      "Inference time:  2.9433112144470215\n",
      "Model: model_1, Inference time: 2.9433s\n",
      "Inference time:  2.7108356952667236\n",
      "Model: model_1, Inference time: 2.7108s\n",
      "Inference time:  2.282961845397949\n",
      "Model: model_2, Inference time: 2.2830s\n",
      "Inference time:  2.1103034019470215\n",
      "Model: model_1, Inference time: 2.1103s\n",
      "Inference time:  2.4183077812194824\n",
      "Model: model_2, Inference time: 2.4183s\n",
      "Inference time:  2.363987445831299\n",
      "Model: model_2, Inference time: 2.3640s\n",
      "Inference time:  3.6010053157806396\n",
      "Model: model_1, Inference time: 3.6010s\n",
      "Inference time:  2.180482864379883\n",
      "Model: model_2, Inference time: 2.1805s\n",
      "Inference time:  3.2255442142486572\n",
      "Model: model_1, Inference time: 3.2255s\n",
      "Inference time:  2.210425615310669\n",
      "Model: model_2, Inference time: 2.2104s\n",
      "Inference time:  3.2972943782806396\n",
      "Model: model_1, Inference time: 3.2973s\n",
      "Inference time:  2.134772300720215\n",
      "Model: model_2, Inference time: 2.1348s\n",
      "Inference time:  3.819831609725952\n",
      "Model: model_1, Inference time: 3.8198s\n",
      "Inference time:  1.7263028621673584\n",
      "Model: model_2, Inference time: 1.7263s\n",
      "Inference time:  3.4356181621551514\n",
      "Model: model_1, Inference time: 3.4356s\n",
      "Inference time:  1.4954218864440918\n",
      "Model: model_2, Inference time: 1.4954s\n",
      "Inference time:  2.976686716079712\n",
      "Model: model_1, Inference time: 2.9767s\n",
      "Inference time:  2.821319341659546\n",
      "Model: model_1, Inference time: 2.8213s\n",
      "Inference time:  2.904136896133423\n",
      "Model: model_2, Inference time: 2.9041s\n",
      "Inference time:  1.6860907077789307\n",
      "Model: model_2, Inference time: 1.6861s\n",
      "Inference time:  3.221395969390869\n",
      "Model: model_1, Inference time: 3.2214s\n",
      "Inference time:  0.8400278091430664\n",
      "Model: model_2, Inference time: 0.8400s\n",
      "Inference time:  3.4149436950683594\n",
      "Model: model_1, Inference time: 3.4149s\n",
      "Inference time:  3.1601009368896484\n",
      "Model: model_1, Inference time: 3.1601s\n",
      "Inference time:  2.1332175731658936\n",
      "Model: model_2, Inference time: 2.1332s\n",
      "Inference time:  2.0362401008605957\n",
      "Model: model_2, Inference time: 2.0362s\n",
      "Inference time:  3.3590381145477295\n",
      "Model: model_1, Inference time: 3.3590s\n",
      "Inference time:  2.6231441497802734\n",
      "Model: model_1, Inference time: 2.6231s\n",
      "Inference time:  2.354637384414673\n",
      "Model: model_2, Inference time: 2.3546s\n",
      "Inference time:  1.9640562534332275\n",
      "Model: model_2, Inference time: 1.9641s\n",
      "Inference time:  3.0882840156555176\n",
      "Model: model_1, Inference time: 3.0883s\n",
      "Inference time:  2.2382705211639404\n",
      "Model: model_2, Inference time: 2.2383s\n",
      "Inference time:  3.235353946685791\n",
      "Model: model_1, Inference time: 3.2354s\n",
      "Inference time:  1.8116114139556885\n",
      "Model: model_2, Inference time: 1.8116s\n",
      "Inference time:  2.386467218399048\n",
      "Model: model_1, Inference time: 2.3865s\n",
      "Inference time:  1.7908358573913574\n",
      "Model: model_1, Inference time: 1.7908s\n",
      "Inference time:  2.1883585453033447\n",
      "Model: model_2, Inference time: 2.1884s\n",
      "Inference time:  2.5552356243133545\n",
      "Model: model_2, Inference time: 2.5552s\n",
      "Inference time:  3.6067047119140625\n",
      "Model: model_1, Inference time: 3.6067s\n",
      "Inference time:  1.966493844985962\n",
      "Model: model_2, Inference time: 1.9665s\n",
      "Inference time:  3.7760560512542725\n",
      "Model: model_1, Inference time: 3.7761s\n",
      "Inference time:  2.8260273933410645\n",
      "Model: model_1, Inference time: 2.8260s\n",
      "Inference time:  1.773237943649292\n",
      "Model: model_2, Inference time: 1.7732s\n",
      "Inference time:  2.0671768188476562\n",
      "Model: model_2, Inference time: 2.0672s\n",
      "Inference time:  4.398674249649048\n",
      "Model: model_1, Inference time: 4.3987s\n",
      "Inference time:  3.770282030105591\n",
      "Model: model_1, Inference time: 3.7703s\n",
      "Inference time:  2.498840093612671\n",
      "Model: model_2, Inference time: 2.4988s\n",
      "Inference time:  2.71000075340271\n",
      "Model: model_2, Inference time: 2.7100s\n",
      "Inference time:  3.3718066215515137\n",
      "Model: model_1, Inference time: 3.3718s\n",
      "Inference time:  1.9506163597106934\n",
      "Model: model_2, Inference time: 1.9506s\n",
      "Inference time:  3.3752713203430176\n",
      "Model: model_1, Inference time: 3.3753s\n",
      "Inference time:  0.8323607444763184\n",
      "Model: model_2, Inference time: 0.8324s\n",
      "Inference time:  2.7444005012512207\n",
      "Model: model_1, Inference time: 2.7444s\n",
      "Inference time:  2.40912127494812\n",
      "Model: model_2, Inference time: 2.4091s\n",
      "Inference time:  3.553382158279419\n",
      "Model: model_1, Inference time: 3.5534s\n",
      "Inference time:  2.021660804748535\n",
      "Model: model_2, Inference time: 2.0217s\n",
      "Inference time:  3.1927273273468018\n",
      "Model: model_1, Inference time: 3.1927s\n",
      "Inference time:  1.8434910774230957\n",
      "Model: model_2, Inference time: 1.8435s\n",
      "Inference time:  3.097360849380493\n",
      "Model: model_1, Inference time: 3.0974s\n",
      "Inference time:  2.8917226791381836\n",
      "Model: model_1, Inference time: 2.8917s\n",
      "Inference time:  2.7530264854431152\n",
      "Model: model_2, Inference time: 2.7530s\n",
      "Inference time:  2.1325178146362305\n",
      "Model: model_2, Inference time: 2.1325s\n",
      "Inference time:  3.0650131702423096\n",
      "Model: model_1, Inference time: 3.0650s\n",
      "Inference time:  2.1828038692474365\n",
      "Model: model_2, Inference time: 2.1828s\n",
      "Inference time:  3.5673813819885254\n",
      "Model: model_1, Inference time: 3.5674s\n",
      "Inference time:  1.4808390140533447\n",
      "Model: model_2, Inference time: 1.4808s\n",
      "Inference time:  2.6756207942962646\n",
      "Model: model_1, Inference time: 2.6756s\n",
      "Inference time:  1.4969544410705566\n",
      "Model: model_2, Inference time: 1.4970s\n",
      "Inference time:  2.823373556137085\n",
      "Model: model_1, Inference time: 2.8234s\n",
      "Inference time:  3.1359853744506836\n",
      "Model: model_1, Inference time: 3.1360s\n",
      "Inference time:  2.5246429443359375\n",
      "Model: model_2, Inference time: 2.5246s\n",
      "Inference time:  1.8182759284973145\n",
      "Model: model_2, Inference time: 1.8183s\n",
      "Inference time:  4.279858350753784\n",
      "Model: model_1, Inference time: 4.2799s\n",
      "Inference time:  3.681504249572754\n",
      "Model: model_1, Inference time: 3.6815s\n",
      "Inference time:  2.0674760341644287\n",
      "Model: model_2, Inference time: 2.0675s\n",
      "Inference time:  2.0413296222686768\n",
      "Model: model_2, Inference time: 2.0413s\n",
      "Inference time:  3.481628656387329\n",
      "Model: model_1, Inference time: 3.4816s\n",
      "Inference time:  1.8463594913482666\n",
      "Model: model_2, Inference time: 1.8464s\n",
      "Inference time:  3.292407751083374\n",
      "Model: model_1, Inference time: 3.2924s\n",
      "Inference time:  2.413015842437744\n",
      "Model: model_2, Inference time: 2.4130s\n",
      "Inference time:  2.965132713317871\n",
      "Model: model_1, Inference time: 2.9651s\n",
      "Inference time:  1.8304126262664795\n",
      "Model: model_2, Inference time: 1.8304s\n",
      "Inference time:  3.042543411254883\n",
      "Model: model_1, Inference time: 3.0425s\n",
      "Inference time:  1.8415768146514893\n",
      "Model: model_2, Inference time: 1.8416s\n",
      "Inference time:  3.083641290664673\n",
      "Model: model_1, Inference time: 3.0836s\n",
      "Inference time:  2.0213706493377686\n",
      "Model: model_2, Inference time: 2.0214s\n",
      "Inference time:  3.303208112716675\n",
      "Model: model_1, Inference time: 3.3032s\n",
      "Inference time:  3.3738996982574463\n",
      "Model: model_1, Inference time: 3.3739s\n",
      "Inference time:  2.3226423263549805\n",
      "Model: model_2, Inference time: 2.3226s\n",
      "Inference time:  2.066845655441284\n",
      "Model: model_2, Inference time: 2.0668s\n",
      "Inference time:  3.755528211593628\n",
      "Model: model_1, Inference time: 3.7555s\n",
      "Inference time:  3.3639214038848877\n",
      "Model: model_1, Inference time: 3.3639s\n",
      "Inference time:  1.9148693084716797\n",
      "Model: model_2, Inference time: 1.9149s\n",
      "Inference time:  2.4343578815460205\n",
      "Model: model_2, Inference time: 2.4344s\n",
      "Inference time:  3.6746301651000977\n",
      "Model: model_1, Inference time: 3.6746s\n",
      "Inference time:  1.891197919845581\n",
      "Model: model_2, Inference time: 1.8912s\n",
      "Inference time:  3.180624485015869\n",
      "Model: model_1, Inference time: 3.1806s\n",
      "Inference time:  1.9664807319641113\n",
      "Model: model_2, Inference time: 1.9665s\n",
      "Inference time:  4.024239540100098\n",
      "Model: model_1, Inference time: 4.0242s\n",
      "Inference time:  3.742830991744995\n",
      "Model: model_1, Inference time: 3.7428s\n",
      "Inference time:  2.4771995544433594\n",
      "Model: model_2, Inference time: 2.4772s\n",
      "Inference time:  1.7527010440826416\n",
      "Model: model_2, Inference time: 1.7527s\n",
      "Inference time:  3.599787473678589\n",
      "Model: model_1, Inference time: 3.5998s\n",
      "Inference time:  1.322443962097168\n",
      "Model: model_2, Inference time: 1.3224s\n",
      "Inference time:  3.3718180656433105\n",
      "Model: model_1, Inference time: 3.3718s\n",
      "Inference time:  3.1025547981262207\n",
      "Model: model_1, Inference time: 3.1026s\n",
      "Inference time:  3.3150296211242676\n",
      "Model: model_2, Inference time: 3.3150s\n",
      "Inference time:  2.8536388874053955\n",
      "Model: model_1, Inference time: 2.8536s\n",
      "Inference time:  2.1137027740478516\n",
      "Model: model_2, Inference time: 2.1137s\n",
      "Inference time:  2.1117656230926514\n",
      "Model: model_2, Inference time: 2.1118s\n",
      "Inference time:  3.4383251667022705\n",
      "Model: model_1, Inference time: 3.4383s\n",
      "Inference time:  3.321835994720459\n",
      "Model: model_1, Inference time: 3.3218s\n",
      "Inference time:  2.711374044418335\n",
      "Model: model_2, Inference time: 2.7114s\n",
      "Inference time:  2.0057904720306396\n",
      "Model: model_2, Inference time: 2.0058s\n",
      "Inference time:  2.8882834911346436\n",
      "Model: model_1, Inference time: 2.8883s\n",
      "Inference time:  2.439507007598877\n",
      "Model: model_2, Inference time: 2.4395s\n",
      "Inference time:  3.044609785079956\n",
      "Model: model_1, Inference time: 3.0446s\n",
      "Inference time:  2.135159492492676\n",
      "Model: model_2, Inference time: 2.1352s\n",
      "Inference time:  3.0107295513153076\n",
      "Model: model_1, Inference time: 3.0107s\n",
      "Inference time:  2.2090063095092773\n",
      "Model: model_2, Inference time: 2.2090s\n",
      "Inference time:  3.007481813430786\n",
      "Model: model_1, Inference time: 3.0075s\n",
      "Inference time:  1.7912046909332275\n",
      "Model: model_2, Inference time: 1.7912s\n",
      "Inference time:  3.0740795135498047\n",
      "Model: model_1, Inference time: 3.0741s\n",
      "Inference time:  2.833883285522461\n",
      "Model: model_1, Inference time: 2.8339s\n",
      "Inference time:  2.0658044815063477\n",
      "Model: model_2, Inference time: 2.0658s\n",
      "Inference time:  1.967451810836792\n",
      "Model: model_2, Inference time: 1.9675s\n",
      "Inference time:  2.431091785430908\n",
      "Model: model_1, Inference time: 2.4311s\n",
      "Inference time:  1.8166782855987549\n",
      "Model: model_2, Inference time: 1.8167s\n",
      "Inference time:  2.7534267902374268\n",
      "Model: model_1, Inference time: 2.7534s\n",
      "Inference time:  2.0449202060699463\n",
      "Model: model_2, Inference time: 2.0449s\n",
      "Inference time:  3.278959274291992\n",
      "Model: model_1, Inference time: 3.2790s\n",
      "Inference time:  1.9312529563903809\n",
      "Model: model_2, Inference time: 1.9313s\n",
      "Inference time:  3.030092239379883\n",
      "Model: model_1, Inference time: 3.0301s\n",
      "Inference time:  1.8634121417999268\n",
      "Model: model_1, Inference time: 1.8634s\n",
      "Inference time:  1.752227544784546\n",
      "Model: model_2, Inference time: 1.7522s\n",
      "Inference time:  1.8531548976898193\n",
      "Model: model_2, Inference time: 1.8532s\n",
      "Inference time:  3.320453643798828\n",
      "Model: model_1, Inference time: 3.3205s\n",
      "Inference time:  2.2676682472229004\n",
      "Model: model_1, Inference time: 2.2677s\n",
      "Inference time:  2.382493019104004\n",
      "Model: model_2, Inference time: 2.3825s\n",
      "Inference time:  2.0714125633239746\n",
      "Model: model_2, Inference time: 2.0714s\n",
      "Inference time:  3.3535501956939697\n",
      "Model: model_1, Inference time: 3.3536s\n",
      "Inference time:  2.3998422622680664\n",
      "Model: model_2, Inference time: 2.3998s\n",
      "Inference time:  2.762963056564331\n",
      "Model: model_1, Inference time: 2.7630s\n",
      "Inference time:  2.1223065853118896\n",
      "Model: model_2, Inference time: 2.1223s\n",
      "Inference time:  3.199247360229492\n",
      "Model: model_1, Inference time: 3.1992s\n",
      "Inference time:  1.624729871749878\n",
      "Model: model_2, Inference time: 1.6247s\n",
      "Inference time:  3.08988094329834\n",
      "Model: model_1, Inference time: 3.0899s\n",
      "Inference time:  2.9228761196136475\n",
      "Model: model_1, Inference time: 2.9229s\n",
      "Total processing time: 475.1140s\n",
      "Total samples processed: 336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "475.11402463912964"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "parallel_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d317850-f9d3-42ba-98d9-89722657315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "start_time = time.time()\n",
    "dataset = load_dataset('MLCommons/peoples_speech', \"microset\", split='train', streaming=True)\n",
    "for sample in dataset:\n",
    "    input_features = processor(sample[\"audio\"][\"array\"], sampling_rate=sample[\"audio\"][\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    t = time.time()\n",
    "    y1 = model.generate(input_features)\n",
    "    print(f\"Elapsed inf2: {time.time()-t}\")\n",
    "    t = time.time()\n",
    "    # print(f\"Tokens inf2: {y1}\")\n",
    "    t1 = processor.batch_decode(y1, skip_special_tokens=True)\n",
    "    print(t1)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d91af-3383-4444-8817-6505d882674b",
   "metadata": {},
   "source": [
    "## Deploy compiled models on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a846b3-2dd6-4f54-9b44-a879088b04b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./whisper_large-v3_1_neuron_encoder.pt\n",
      "./whisper_large-v3_1_128_neuron_proj.pt\n",
      "./whisper_large-v3_1_128_neuron_decoder.pt\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf model.tar.gz -C neuron_model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb3470da-870a-44a7-81ba-a45f8c74b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_REGION\"] = \"us-west-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c3bf9a-7b3a-452e-bc39-fed90439dbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, serializers, deserializers\n",
    "\n",
    "boto_session = boto3.Session(region_name=\"us-west-2\")\n",
    "sess = sagemaker.Session(boto_session=boto_session)\n",
    "role = sagemaker.get_execution_role(sagemaker_session=sess)\n",
    "sess_bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81cab2ac-bfd8-415a-b552-d6b973345e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::392304288222:role/EC2SageMakerPlayGroundRole\n",
      "sagemaker bucket: sagemaker-us-west-2-392304288222\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "print(f'sagemaker role arn: {role}')\n",
    "print(f'sagemaker bucket: {sess_bucket}')\n",
    "print(f'sagemaker session region: {sess.boto_region_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c802cdb8-ee18-4f09-a4df-1d73a8da7726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model artifacts uploaded to s3://sagemaker-us-west-2-392304288222/inf2_compiled_whisper_model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "prefix = \"inf2_compiled_whisper_model\"\n",
    "s3_model_path = f\"s3://{sess_bucket}/{prefix}\"\n",
    "\n",
    "# upload model.tar.gz\n",
    "s3_model_uri = S3Uploader.upload(\n",
    "    local_path=\"model.tar.gz\", desired_s3_uri=s3_model_path,\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "print(f\"model artifacts uploaded to {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72c047-fdea-4a2c-b72f-385b528ce751",
   "metadata": {},
   "source": [
    "### 推論用のコードの作成\n",
    "\n",
    "https://github.com/aws/deep-learning-containers/blob/master/available_images.md で最適なイメージを見つけられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "737b5eed-f489-4918-829c-4b24d89e39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_role = \"arn:aws:iam::392304288222:role/service-role/AmazonSageMaker-ExecutionRole-20250130T094469\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5937fcf3-2395-4392-a1e3-883a043e250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_uri = \"s3://sagemaker-us-west-2-392304288222/inf2_compiled_whisper_model/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c0f4c69-55d3-415a-8d0c-2986cdf7c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import DataSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Define serializers and deserializer\n",
    "audio_serializer = DataSerializer(content_type=\"audio/x-audio\")\n",
    "deserializer = JSONDeserializer()\n",
    "\n",
    "ecr_image = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference-neuronx:2.5.1-neuronx-py310-sdk2.21.0-ubuntu22.04\"\n",
    "# for hugging face container\n",
    "# ecr_image = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference-neuronx:2.1.2-transformers4.36.2-neuronx-py310-sdk2.18.0-ubuntu20.04\"\n",
    "\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_uri,\n",
    "    role=sagemaker_role,\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=ecr_image,\n",
    "    model_server_workers=1,\n",
    "    sagemaker_session=sess,\n",
    "    env={\n",
    "        \"chunk_length_s\":\"30\",\n",
    "        'MMS_MAX_REQUEST_SIZE': '2000000000',\n",
    "        'MMS_MAX_RESPONSE_SIZE': '2000000000',\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '900'\n",
    "    }\n",
    ")\n",
    "\n",
    "pytorch_model._is_compiled_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d90b02e-e4d2-451b-871e-22e5e9b1cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Predictor\n",
    "predictor = Predictor(\n",
    "    endpoint_name=\"pytorch-inference-neuronx-ml-inf2-2025-03-19-11-30-08-598\",\n",
    "    sagemaker_session=sess,\n",
    "    serializer=audio_serializer,\n",
    "    deserializer=deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e0b0c9-8eb8-4209-b96d-ed4488a19dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!pytorch-inference-neuronx-ml-inf2-ml-in-2025-03-19-09-03-40-434\n",
      "CPU times: user 15min 9s, sys: 17.2 s, total: 15min 27s\n",
      "Wall time: 24min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = pytorch_model.deploy(\n",
    "    instance_type=\"ml.inf2.8xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    serializer=audio_serializer,\n",
    "    deserializer=deserializer\n",
    ")\n",
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03ec9ff0-46f3-4d89-81b5-1b7aae0833b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: soundfile in /opt/aws_neuronx_venv_pytorch_2_5_transformers/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/aws_neuronx_venv_pytorch_2_5_transformers/lib/python3.10/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/aws_neuronx_venv_pytorch_2_5_transformers/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92a63515-9c91-4f35-9fae-f1216d0972bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b080e34b-f1af-4657-9a37-4053f2d4c86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00335.flac',\n",
       " 'audio': {'path': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00335.flac',\n",
       "  'array': array([-8.28857422e-02, -6.21337891e-02, -4.33654785e-02, ...,\n",
       "          3.05175781e-05, -6.83593750e-03, -7.62939453e-03]),\n",
       "  'sampling_rate': 16000},\n",
       " 'duration_ms': 14800,\n",
       " 'text': \"are actually farming so that we can then bring back and collect our tax rate on a true level it's just you know they file the paper there's no follow through in the taxation collection so\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93fb52c1-f154-48c4-9b74-5d7cab7eb740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 μs, sys: 0 ns, total: 6 μs\n",
      "Wall time: 13.4 μs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c325469a313542668504a89a27b96591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed inf2: 2.4147889614105225\n",
      "[\" I wanted to just share a few things, but I'm gonna not share as much as I wanted to share because we are starting late. I'd like to get this thing going so we all get home at a decent hour. This election is very important to us.\"]\n",
      "Elapsed inf2: 1.9875483512878418\n",
      "[\" we support agriculture to the tune of 0.4%. Oh no wait, I made a mistake. This year they lowered it from 0.4% to 0.38%. And in the same breath they're saying food\"]\n",
      "Elapsed inf2: 1.4311702251434326\n",
      "[\" So it doesn't feel very secure to me as a farmer to hear that. And my family and I, we've been farming here since 1993.\"]\n",
      "Elapsed inf2: 1.494741678237915\n",
      "[' Last year we produced 21,000 pounds of food for the community on 2,000 square feet. So unless we were that efficient to produce that much food,']\n",
      "Elapsed inf2: 1.7296266555786133\n",
      "[' commons here in the spirit of being able to grow our food here locally. So we started as an organization actually in 2009, but really in 2010. March of 2010, we had our first meeting']\n",
      "Elapsed inf2: 1.4665827751159668\n",
      "[\" Maui and now we have 10 chapters across the islands and about 900 members so we are growing exponentially and we're fortunate to know that we have not only\"]\n",
      "Elapsed inf2: 1.8712341785430908\n",
      "[\" farmers, but gardeners and foodies alike who value our mission and what we're about in rejuvenating our lands and also at the same time advocating for our local food production. So what we've done as an\"]\n",
      "Elapsed inf2: 2.272108793258667\n",
      "[\" organization has put together a five-point plan and you'll hear about that five-point plan tonight in our questions. And that five-point plan basically deals with the whole system of agriculture. What makes up a whole system of agriculture? And as we see it is\"]\n",
      "Elapsed inf2: 3.0246849060058594\n",
      "[\" at 40 years old getting into farming. Didn't know what I was doing. I was a gardener. But I had the passion. And that's what I still have today. And that's what's sustained our family farm, along with my wife's passion and our son, who works full time on the farm, and our\"]\n",
      "Elapsed inf2: 2.245765447616577\n",
      "[\" daughter, who came out of it. Actually, she designs and fabricates her own women's swimwear line. So here she grew up in a farm family, knew about being an entrepreneur, and she went and gone, I'm not going to go work for somebody else.\"]\n",
      "Elapsed inf2: 1.9362101554870605\n",
      "[\" has her own business in that respect. So there's a lot of benefits to our economy that represents a family farm. The multiplier effect, we like to call it. So outside of workforce development, we support agricultural land trusts.\"]\n",
      "Elapsed inf2: 2.281175136566162\n",
      "[\" get out once they get out. And that would be enforced in a way that we wouldn't have any quote unquote gentlemen of states, they would be active farms. And so we have a man in our organization who's actually a board member of our 501 foundation, Dale Bonar,\"]\n",
      "Elapsed inf2: 1.9927146434783936\n",
      "[\" advocating and working on developing that. Third thing is nutrient recycling centers. We're developing and advocating for those in our regions. See, the reason why we have so many chapters is because we want to\"]\n",
      "Elapsed inf2: 2.6353044509887695\n",
      "[\" build our agricultural strength regionally. We want to, you know, when you're growing things in Hana, it's a lot different than you're growing in Lahaina where James is right now, you know. And so each region has its own issues and its own challenges and its own benefits.\"]\n",
      "Elapsed inf2: 2.076486825942993\n",
      "[' And we want to highlight those and bring that to where we can have a supportive system in place. So nutrient recycling, our nutrients back onto the land to rejuvenate the soils that have been depleted by plantation agriculture over a long period of time.']\n",
      "Elapsed inf2: 1.866511583328247\n",
      "[\" is an important aspect of what we represent. And the fourth thing is food hubs. Have aggregates, places where we can, as farmers, bring all our produce and then have that aggregate out, whether it's fresh and or\"]\n",
      "Elapsed inf2: 2.2294042110443115\n",
      "[\" You know, and it's so beautiful to see these kind of farms, these boutique farms springing up all over the place. So it's important that we support our farmers, first and foremost, making a living at what they love to do. And secondly, to put across this\"]\n",
      "Elapsed inf2: 2.1959176063537598\n",
      "[\" five-point plan and to have you, the folks that are running for office, that can get into office to support us in this respect because we're poised to work with anyone who is willing to work with us. So on that note, I'd like to introduce our first\"]\n",
      "Elapsed inf2: 2.06247615814209\n",
      "[\" But domestic violence doesn't happen in a vacuum. It's a lot of the community issues, things like poverty, homelessness, housing, all the different effects of living on an island community, and the cost of living, and all those kinds\"]\n",
      "Elapsed inf2: 2.219057559967041\n",
      "[\" I know on a very small scale what farmers experience on a large scale, aside from though having to make a living at it. So I'm not doing it on that level. I'm just trying to raise enough tomatoes for my grandson\"]\n",
      "Elapsed inf2: 1.9425725936889648\n",
      "[\" to eat every morning. So I'm here mostly to learn too. I'm glad to know that the Hawaii Farmers Union is relatively young and so I'm not too far behind the curve and I'm grateful to be\"]\n",
      "Elapsed inf2: 1.927403211593628\n",
      "[' development, sorry for the false start on that. And our comment on that is with the average age of farmers in Hawaii at 60, we can all agree we need to grow a new generation of farmers equipped with the skills to create successful farming']\n",
      "Elapsed inf2: 2.0727925300598145\n",
      "[\" Also, having gotten grants from the county, I know that they have a lot of requirements, but I think when you're looking at a program like this, you're looking at something new and something different. So I think everyone could come with a different set of\"]\n",
      "Elapsed inf2: 2.278341293334961\n",
      "[\" goals and they might all be very, very worthy, right? Because you might have somebody who's trying to create a farm. You might have somebody who already has a farm who's trying to get a bigger farm. You might have somebody with a big farm that's trying to invest in infrastructure more\"]\n",
      "Elapsed inf2: 1.938661813735962\n",
      "[\" equipment or something like that. So I think those kinds of grants shouldn't be too restrictive because you need to be able to be creative with new projects. So I would support that because I think the need is here and it's huge.\"]\n",
      "Elapsed inf2: 1.8899235725402832\n",
      "[\" question and the statement and I think of the programs that we have in place, programs that we grew up with like FFA and things like that. I noticed as an adult I don't see as much participation when we're in\"]\n",
      "Elapsed inf2: 1.5999650955200195\n",
      "[\" much anymore and that's something that we need to start to support more in our schools. To support a fund, I'd like to see that apprenticeship programs incorporate alternative farming practices.\"]\n",
      "Elapsed inf2: 2.0120291709899902\n",
      "[' you would want a beginning farmer program to have in order to win your support? Absolutely. Absolutely. In my thoughts in a farm apprenticeship program and any apprenticeship program is the importance of diversity in their training. As a young farmer,']\n",
      "Elapsed inf2: 2.5207488536834717\n",
      "[\" in pest control, in soil maintenance, which is a big issue that we'll be discussing in a little bit. And especially, I think a lot of people when they think about farm apprenticeships, they think about manual labor. So that's why I would like to see more training,\"]\n",
      "Elapsed inf2: 1.7880940437316895\n",
      "[' more education in the program so that the farmers that we produce are going to be able to accept and be able to deal with some of the change and diversity in the market. Thank you.']\n",
      "Elapsed inf2: 1.7764813899993896\n",
      "[\" Thank you all. Our next question is strangely enough on the same theme, only it's about nutrient cycling centers and soil health and regenerative agriculture. So our lead-in comment, currently many of our Hawaii\"]\n",
      "Elapsed inf2: 1.8315033912658691\n",
      "[\" farmers must purchase imported nutrient farm amendments. It's an expense for farmers that's passed down to the consumer. In the meantime, we accept 20,000 tons of food waste at the Maui County dump that could be\"]\n",
      "Elapsed inf2: 1.2115020751953125\n",
      "[' One of the barriers is definitely that many of our leaders are not privy to the background of all the different farming']\n",
      "Elapsed inf2: 1.6547069549560547\n",
      "[' practices. In the last two years of my degree, I focused on the anthropology of agriculture and how different countries throughout the world are now reverting back to their indigenous agriculture systems in Brazil,']\n",
      "Elapsed inf2: 1.6549711227416992\n",
      "[\" in Korea and learning that the system that worked all along was the best system for the place, which makes perfect sense. But we've been, I think, in a place where we've\"]\n",
      "Elapsed inf2: 2.075417995452881\n",
      "[\" We have multiple hotels here who do these huge catering jobs and have all this extra food. And I actually know that because sometimes the food ends up at our shelter when it's good. But there's all this byproduct. When you're prepping food,\"]\n",
      "Elapsed inf2: 2.044184923171997\n",
      "[\" all that stuff, there's so much food just from the hotels and catering companies that could end up in composting. That makes perfect sense to me. I think part of the problem and the barrier is that we, similar to what Napua said,\"]\n",
      "Elapsed inf2: 2.167818069458008\n",
      "[\" we don't know better yet. Like we're just learning about that, that we could take all that food and turn it into wonderful rich soil is a, it's not a new concept by any means, it's a very old concept, but we've gotten used to doing\"]\n",
      "Elapsed inf2: 2.0716967582702637\n",
      "[\" educate us as county council and as leaders throughout the state about the importance of that. Thank you. Thank you very much, all of you. I don't know if we mentioned this, this race actually has four people running, but we\"]\n",
      "Elapsed inf2: 1.9615743160247803\n",
      "[' We need an empty seat. Okay, food hubs. Across the nation, food hubs are becoming solutions for centralizing food processing and distribution, increasing food production capabilities for small farmers by paving the way for']\n",
      "Elapsed inf2: 1.9720239639282227\n",
      "[' cooperatives. Our five point plan is working with the statewide farm to school initiative for growing food for the DOE school lunch program. Now all three of you, you have one minute. Please describe benefits you can imagine']\n",
      "Elapsed inf2: 1.8619287014007568\n",
      "[' for the citizens of Maui that would result from the Maui County facilitating and funding a food hub. Let me repeat that. Please describe benefits you can imagine for the citizens of Maui that would result from Maui County']\n",
      "Elapsed inf2: 1.9219589233398438\n",
      "[\" fishermen up there selling fresh fish. You've got people growing and cooking with their own food and selling wonderful fresh food at the market. So something like that. I also think that, oh, because one of the biggest things that's\"]\n",
      "Elapsed inf2: 1.8350107669830322\n",
      "[\" happened for my family is this fresh eggs. You know, getting organic eggs at Costco is great, but getting locally grown eggs that are all different sizes and colors and when there's a huge difference. So that was an\"]\n",
      "Elapsed inf2: 2.4480013847351074\n",
      "[\" education for me. And one of my things that I keep saying is, I grew up in a time where things were different and going to the supermarket became a luxury in that if you had any status, you go to the market, you don't have to have your own chickens. But we're reclaiming that now.\"]\n",
      "Elapsed inf2: 2.3086678981781006\n",
      "[' And what happened? People grew their own food. People worked on barter systems. People were able to have their own food hubs in their communities where they were able to trade and barter their goods for the things they needed. Why do I think food hubs are important? Because a food hub for sustainable']\n",
      "Elapsed inf2: 2.3219971656799316\n",
      "[' that would be involved with that. The education for these people. This is part of the five-point plan for the Farmers Union in my mind to bring apart this new change in our agricultural system and how we view our food, what we eat and how we eat it. So I would be completely']\n",
      "Elapsed inf2: 1.8600966930389404\n",
      "[' for developing these food hubs for the idea of training apprenticeship programs bringing healthy food into our community and developing through the county of Maui ways that we can use and certify these organic farms so that a food can be given to']\n",
      "Elapsed inf2: 2.0686051845550537\n",
      "[\" So we're going to switch to policy a little bit and we're going to have a separate question for each of you. We have specific questions with each of you in mind. Our topic is the farmland zoning and affordable land trusts. In other words,\"]\n",
      "Elapsed inf2: 1.6047532558441162\n",
      "[\" Eric, you have two minutes. So here's your question. Our organization supports the concepts of farmers living on the land they farm and lease through an agricultural land trust.\"]\n",
      "Elapsed inf2: 2.3545944690704346\n",
      "[\" ideas would you propose in moving in this direction so that it would be actualized? In other words, how can we make it so that people can lease farmlands and actually live on them? That's a wonderful question. It's an interesting thing. I think we're looking at\"]\n",
      "Elapsed inf2: 2.323371171951294\n",
      "[\" housing, start developing more sustainable lands that these farmers are actually putting more interest into their land as they're developing the cost and the resources that they can be gained from that. As we're developing that we need to look, I think we need to look at that\"]\n",
      "Elapsed inf2: 2.2836666107177734\n",
      "[' community is to start getting on some big business to say what is your plan especially Alexander and Baldwin how are you planning on developing this for as you they have stated for use for individual farmland once that is together then I think we can move forward as a group towards a project to']\n",
      "Elapsed inf2: 1.9623122215270996\n",
      "[' speaking with right now. So these are three of the four candidates for the upcountry consul seat. Stacey, you have your own question, two minutes. What are your ideas for changing Ag zoning that will allow for more options for farm']\n",
      "Elapsed inf2: 1.9496819972991943\n",
      "[\" worker dwellings, including temporary structures, such as the new trend of tiny houses and yurts. I think that's an excellent idea. I love the tiny house idea, and I think that we do need to change some of our\"]\n",
      "Elapsed inf2: 2.6412408351898193\n",
      "[\" regulations, if you will, to allow for that. Because right now it's kind of complicated and you really can't just put up a yurt. You still need a permit. If you have a tiny house, you need to put it on wheels. I mean, it's kind of silly. But I think that as a county, if we're\"]\n",
      "Elapsed inf2: 1.8945956230163574\n",
      "[\" If we're really committed to one, affordable housing, which we keep saying we are, and if we're really committed to farming and growing our food and supporting local businesses, these are all very small businesses we're trying to support.\"]\n",
      "Elapsed inf2: 1.9517300128936768\n",
      "[\" then we need to find ways to make that happen. And so I would support that. I think the concern is that sometimes people will say that it's workforce housing and build a mansion on their ag land. So I think that we would want\"]\n",
      "Elapsed inf2: 2.100177049636841\n",
      "[\" want to monitor that and have an enforcement part of this as well to make sure, because it's one thing, yes, we absolutely want to support workforce housing if you're working on the farm. That's very important. We all have to have support and housing.\"]\n",
      "Elapsed inf2: 2.5983283519744873\n",
      "[\" you know, looking at, not everybody's paying their fair share sometimes on taxes. Some people are paying too much, some people are not paying enough. So to have an enforcement piece to make sure everybody's paying their fair share, that's really important to me. I think we need to look at that. And that that would actually pay for itself\"]\n",
      "Elapsed inf2: 1.4015018939971924\n",
      "[' pretty quickly. I also wanted to say that we have a big housing crisis here. So this is a solution, I think, to several problems.']\n",
      "Elapsed inf2: 1.4873337745666504\n",
      "[\" the housing and the ag and the growing food. So I think it's a good solution. So I'm really glad you're asking those questions. Thank you.\"]\n",
      "Elapsed inf2: 3.4507293701171875\n",
      "[' NAPUA, YOU HAVE TWO MINUTES AND YOUR QUESTION IS COMPLETELY DIFFERENT. GIVEN WHAT IT COSTS FOR THE AVERAGE FARMER TO RENT A HOUSE, LEASE FARM LAND, PAY FOR EQUIPMENT, PAY FOR IMPORTED AMENDMENTS AND INPUTS, IRRIGATION COSTS, ET CETERA, IN OTHER WORDS,']\n",
      "Elapsed inf2: 1.957531213760376\n",
      "[\" There's a lot of costs if you want to farm. What do you think it will take to make farming more successful enterprise? And what could you do about it if you're elected? I think it is going to take the cooperation\"]\n",
      "Elapsed inf2: 1.5751581192016602\n",
      "[' of county and state government to be able to put aside those funds. And just touching on the other questions, I believe in order for us to change what is']\n",
      "Elapsed inf2: 2.206594705581665\n",
      "[\" is acceptable, an AG that's gonna take a change to the Hawaii Revised Statutes or a change to our county charter, but that's something as policy makers that is in our power to do. And I think we need to be able to look at the\"]\n",
      "Elapsed inf2: 2.0426480770111084\n",
      "[\" policies that have been in place forever and reexamine if they truly suit us today. And if they don't, then we need to look at what our community really needs. And funding, I would be able to bring different\"]\n",
      "Elapsed inf2: 1.8678522109985352\n",
      "[' of our community together. I think one of my strengths is being able to reach out to those who are the experts in their field. I readily know that I am not an expert in all fields and I am aware of']\n",
      "Elapsed inf2: 1.7505686283111572\n",
      "[\" that and I very much honor and respect the expertise of those people who are our experts. When I was on the State Land Use Commission, I did vote against a very controversial development on O'ahu because it\"]\n",
      "Elapsed inf2: 1.8681323528289795\n",
      "[' how much the cost of irrigation would be to develop a new site. And so as policy makers, as government leaders, we need to be able to protect those people who are producing food. We need to be able to protect those']\n",
      "Elapsed inf2: 1.6377668380737305\n",
      "[' places that they are currently farming, those places that are currently in ag. And we need to put aside those funds and invest. If food security and food sustainability is our goal, like water']\n",
      "Elapsed inf2: 1.5180115699768066\n",
      "[' infrastructure, like all those things like housing, affordable housing, we need to be able to prioritize and give funding to those places. Mahalo. Thank you so much.']\n",
      "Elapsed inf2: 1.9536573886871338\n",
      "[\" third party a completely one of the thoughts that I've had is maybe it should be a separate entity that's just doing the public trust maybe not necessarily a non-profit but it could be a non-profit but it could be a completely separate\"]\n",
      "Elapsed inf2: 1.4879956245422363\n",
      "[' corporation that runs and maintains that system. Because right now, the challenge is we have a big corporation who has used that water system for its very existence in sugar.']\n",
      "Elapsed inf2: 1.7487797737121582\n",
      "[\" And they built it and they've maintained it, but they've also recouped their investment many times over. So now it's time to share the water with everyone, restore some of the streams that have\"]\n",
      "Elapsed inf2: 1.8970904350280762\n",
      "[\" they've cut the streams off. So the life cycles there have completely changed. And there are farmers along the way. We need to, if our commitment is to diversify agriculture, we're going to need to share that water.\"]\n",
      "Elapsed inf2: 1.8078117370605469\n",
      "[\" invested interest in it, owning it. Maybe it's the state. I mean, maybe that's the best answer. Maybe it's a third party. I would like to investigate that more. Thank you very much.\"]\n",
      "Elapsed inf2: 1.7221717834472656\n",
      "[' system that needs repair and or replacement. How do you as a candidate see the needed infrastructure being put in while dealing with the multiple entities out there that wish to control the water? Should I repeat that?']\n",
      "Elapsed inf2: 2.307985305786133\n",
      "[\" White State legislature approved Alexander Baldwin to keep the water rights for the next 13 years. That's a complete travesty. That should be immediately re-looked at and changed so that we're not, it's not under corporate control. I believe a lot of that water and that infrastructure that was built\"]\n",
      "Elapsed inf2: 2.537541151046753\n",
      "[' supplies water to the plantation, not counting East Maui irrigation. There was water, vias everywhere. I think we need to get control back of our water system so we can use it to get back to the streams, to get back to our, the people who need it. With that, we need to deal with our water quality.']\n",
      "Elapsed inf2: 2.743053436279297\n",
      "[\" We have to get back to looking at the old ahupua'a system. You know, we have great groups with the watershed partnerships. We have to make sure that the water coming from the mountain is safe, healthy, and clean for our farmers to use. I think we need to look at it as this top-down system, mauka to makai, to\"]\n",
      "Elapsed inf2: 1.6591644287109375\n",
      "[\" protect our water resources and again to reclaim the water that's here on the island to the people who really deserve it and not the large corporations who have abused it. Thank you. Thank you.\"]\n",
      "Elapsed inf2: 1.8113179206848145\n",
      "[\" and not in use. And it's shameful, it's disgraceful when so many people need it. We hear so often about the need of all the different parts of our community that no one entity should be able to\"]\n",
      "Elapsed inf2: 1.3512439727783203\n",
      "[' waste that way. And so I would be very active in looking at the policies that concern this. Mahalo. Thank you very much.']\n",
      "Elapsed inf2: 1.6485857963562012\n",
      "[\" economic efficiencies and with the hope that this would replace currently employed practices that the farmers union doesn't really support. So knowing that, we have a few questions for you starting with Eric.\"]\n",
      "Elapsed inf2: 1.670039176940918\n",
      "[' What would you do to empower the Hawaii Department of Agriculture and Hawaii Health Department by supporting bills that monitor pesticide drift to protect our health and environment, such as things like product testing, soil']\n",
      "Elapsed inf2: 2.472269296646118\n",
      "[\" citizens in Maui County need to take the helm on that and start doing their own tests. There are organizations, the Department of Water Supply, there's other groups where you can swab your screens. I think we need to find out, especially if you're living next to an agricultural area where there is spraying or you\"]\n",
      "Elapsed inf2: 2.260418176651001\n",
      "[\" suspect to look at what the chemicals are in the area. With that, I have to say that I think a lot of it is up to the individual landowner. I'm against pesticides. In my career in Maui, I did a large stint as a farmer\"]\n",
      "Elapsed inf2: 1.61576247215271\n",
      "[\" Stacy, one minute again. When it's been proven that there are biological applications that can provide solutions to agricultural production issues, what is your position on promoting these over practices that\"]\n",
      "Elapsed inf2: 1.5793068408966064\n",
      "[' use other substances which are well-known hormonal disruptors and possible carcinogens and might cause physical harm to both people and the environment. So the question is about']\n",
      "Elapsed inf2: 1.7814345359802246\n",
      "[\" If there are proven biological applications, what's your position on promoting these over our business as usual practices? Again, I think it comes back to when you know better, now you have to do better.\"]\n",
      "Elapsed inf2: 2.2858035564422607\n",
      "[\" Part of the, I sat on the resolutions committee for the Democratic Party last year, or last convention two years ago, and one of the big things that came up from Kauai was that people, children were being born with horrible birth defects. You couldn't deny it.\"]\n",
      "Elapsed inf2: 2.113513946533203\n",
      "[' There was such a high level of that that was proven to be connected to pesticides and runoff and things like that. And so the party created a position saying that that needed to stop, that we need to be informed and that people needed to know what was']\n",
      "Elapsed inf2: 2.012122631072998\n",
      "[\" happening in their areas because it was so dramatic. I would absolutely support that too. I think the least that we can expect is to know what's going on in our, especially near schools, near our homes, near parks. And if there are\"]\n",
      "Elapsed inf2: 2.0699758529663086\n",
      "[\" biological ways that will work, then we need to look at that. If there are proven ways, then we need to use that instead. Because I know that there are ways that we're just not using because we're not being sort of sold by Dow Chemical.\"]\n",
      "Elapsed inf2: 1.5151658058166504\n",
      "[' parks and our highways, our Department of Parks and Rec, our county managing director, if we can be able to show through experience, through it works, that these alternative']\n",
      "Elapsed inf2: 2.3347251415252686\n",
      "[' METHODS THAT ARE BETTER FOR US WORK, THEN THEY ARE MORE APT TO USE THEM. I WOULD WANT TO CREATE POLICIES TO MAKE US USE THEM. THANK YOU ALL VERY MUCH. WE HAVE ONE LAST QUESTION.']\n",
      "Elapsed inf2: 1.8377294540405273\n",
      "[\" One last question and this one's labeled other but it's for all three of you and we'll give you one minute We have noticed that many of the candidates running this year are freshmen in a field of potentially seasoned councilmen\"]\n",
      "Elapsed inf2: 1.744863748550415\n",
      "[' potentially seasoned council members, how do you see working together with others that may not share your values or point of view in how to address our agricultural needs? And Eric, you can go first, one minute.']\n",
      "Elapsed inf2: 2.1261887550354004\n",
      "[\" and be involved. In any kind of negotiations and any kind of a planning, there is always a need for mediation because they're always conflicting views. As the UNRIC's council member, my goal would be to be there as that mediator to help bring in\"]\n",
      "Elapsed inf2: 2.0212173461914062\n",
      "[\" different parties to communicate well and to come up with a viable solution to every problem because conflict is part of life and as we're seeing in most election processes right now that this is where we're bringing people together and trying to organize to develop the vision of\"]\n",
      "Elapsed inf2: 1.8947091102600098\n",
      "[\" in a field of potentially seasoned council members, how do you see working together with others that may not share your values or point of view in how to address our agricultural needs? First of all, I think it's wonderful that there are\"]\n",
      "Elapsed inf2: 1.841853380203247\n",
      "[\" lot of new people trying to get into public service because I think that we're a testament to the fact that we're ready for something different and so I I I think that's wonderful I also think that for most of my\"]\n",
      "Elapsed inf2: 1.873361587524414\n",
      "[\" career as an advocate I'm working with people who often don't see eye to eye domestic violence was not a very popular conversation in the 80s when I first started doing this work so we brought this to the public we started having\"]\n",
      "Elapsed inf2: 2.0958142280578613\n",
      "[\" conversations. Then we had to engage people to help us in the solution because it was a problem that we couldn't solve by ourselves. And sometimes we had very differing opinions. And so part of the thing that I'm most proud of is creating collaborations that were very\"]\n",
      "Elapsed inf2: 1.6618232727050781\n",
      "[' effective to work on creating laws that protect victims of domestic violence, creating task forces and collaborations and that work together and bring people in from actually, you know, sometimes unpolarized positions.']\n",
      "Elapsed inf2: 1.7747504711151123\n",
      "[\" as an advocate, I have already had that experience of working with groups of people and I would bring that skill. Even as a freshman, I'm not a rookie at working in groups of people. Thank you.\"]\n",
      "Elapsed inf2: 1.6969916820526123\n",
      "[' of how challenging being a candidate is. And I think one of the strengths that I have is my background in education. To be an effective teacher, you need to be able to present the same information']\n",
      "Elapsed inf2: 2.218475580215454\n",
      "[\" a bunch of different ways because you're dealing with students who come from very diverse backgrounds, like our very diverse communities. And so I can't just say it one time and hope they all get it. I have to say it five times in different ways and hope you all get it.\"]\n",
      "Elapsed inf2: 2.4017233848571777\n",
      "[' and to be able to know different ways to say it. I need to look at you as an individual and see where you come from. I want to know where you come from, where your background is, so I know how best to present it to you so that you can get it, so we can get on some']\n",
      "Elapsed inf2: 1.3885273933410645\n",
      "[' common ground. My travels in different countries have also helped me to not just present that information to people here in Hawaii, but people from different countries.']\n",
      "Elapsed inf2: 1.8327865600585938\n",
      "[\" I believe it's my cultural background that helps me to understand those of different cultures. We need to be able to find common ground in order to move forward. And I also understand that although we may disagree on one issue,\"]\n",
      "Elapsed inf2: 1.9025475978851318\n",
      "[\" The issue doesn't define a person. And I think too often we see in leadership today that we are allowing one issue to define people. And as a wonderful community, the community that has helped to raise me, we cannot belittle\"]\n",
      "Elapsed inf2: 2.0374927520751953\n",
      "[\" other to think we are defined by just one issue because we are way more complex than that and we are we're so much better than that also and so I think I've already had experiences with there are people you know I don't agree with our mayor on\"]\n",
      "Elapsed inf2: 1.8157014846801758\n",
      "[\" studying anthropology of agriculture. And it's amazing in India that we talk about water. In India, they have a water temple system. And this is how they manage their water, where the people who designate how that\"]\n",
      "Elapsed inf2: 2.183380365371704\n",
      "[' But it exists and it works. And I think we need to be able to, one, be educated on what works in different parts of the world to be able to bring what is the very best home to Hawaii. We also need to be educated in what always worked here in']\n",
      "Elapsed inf2: 1.9027879238128662\n",
      "[' indigenous systems because we know what what works we know what this I know is made for and we need to be able to consult those experts we need to value that information and that education instead of ignoring it and putting it to the side']\n",
      "Elapsed inf2: 1.5289790630340576\n",
      "[\" So I'm very excited about the vision. I'm excited about this movement. I'm excited to see what we can do together as a community. Mahalo.\"]\n",
      "Elapsed inf2: 2.258941173553467\n",
      "[' And that even as a farmer, other than working with the land, I was involved with pesticide issues, with land use issues, with definitely the water issues that took to keep that farm going and to try and rehabilitate that farm after years of disarray. Through that,']\n",
      "Elapsed inf2: 2.2317636013031006\n",
      "[\" Through all these experiences, I learned so much about the needs of farmers, the needs of the land, the needs of businesses to actually survive in a very competitive and a world market. Again, working with some of our flowers where we're not able to distribute overseas because of being out\"]\n",
      "Elapsed inf2: 1.9659228324890137\n",
      "[' competed due to marketing aspects that happened in the 80s, way before I got involved. Those were all heavy issues. And later, I would love to communicate with everybody to get more ideas to help me understand individual issues, to help...']\n",
      "Elapsed inf2: 1.9722893238067627\n",
      "[' Stacy, do you have any concluding remarks about your positions on agriculture? Or is there a question you wish you would have been asked? And if so, please ask it and respond in two minutes. Well, I really am.']\n",
      "Elapsed inf2: 2.2840652465820312\n",
      "[\" I think I've learned so much in my little garden, and it inspires me. I created a whole program just from a piece of collo that my son got visiting someone's field. He brought it back. He dropped it in a pot, because I didn't have time to grow it\"]\n",
      "Elapsed inf2: 1.944871187210083\n",
      "[' Kiki Kahlo and so I learned a lot in the garden I learned a lot from farmers you know that are doing way more than I am but one of the things that I think as a county we should do is support people who']\n",
      "Elapsed inf2: 2.0189783573150635\n",
      "[\" want to grow food because sometimes there I think we need advocates for farmers and I think the county should create that whether it's in the form of a grant writer or in a in the form of an AG department or but some way to support the\"]\n",
      "Elapsed inf2: 2.0943799018859863\n",
      "[' farmers because you might be really great at growing food and regenerating the soil and doing all the work that needs to go into it and maybe not so great at writing a grant. You know, an RFP just came out which is a request for proposals to']\n",
      "Elapsed inf2: 1.9656691551208496\n",
      "[\" State RFPs are very complex and I don't know, I'm a grant writer, I know how complicated they can be. So I feel like the county would do well to hire a grant writer to help not just the farmers but in this\"]\n",
      "Elapsed inf2: 1.9024536609649658\n",
      "[\" context, certainly the farmers who may not have that skill set. So I would like to see more advocacy for people like the farmers who need that level because there's money out there. We just need to know how to get it.\"]\n",
      "Elapsed inf2: 1.6096234321594238\n",
      "[' I look around the room and I see numerous people who I have provided veterinary services for over the years. I decided to run for the County Council because I have been involved with agriculture']\n",
      "Elapsed inf2: 1.4689061641693115\n",
      "[' for 40 years as a veterinarian providing services for cattle, horses, sheep, goats, and all the small animals you can name, as well as wildlife.']\n",
      "Elapsed inf2: 0.7632348537445068\n",
      "[\" I'm looking forward to the election.\"]\n",
      "Elapsed inf2: 1.4666833877563477\n",
      "[\" We all agree we need to grow a new generation of farmers equipped with the skills to create successful farming enterprises. The Hawaii Farmers Union United Maui Chapter's\"]\n",
      "Elapsed inf2: 1.5545637607574463\n",
      "[' What issues would you want to raise before making such a decision in committee? Dr. Kaufman? Thank you for such a specific question. If you want a new generation of']\n",
      "Elapsed inf2: 2.4057512283325195\n",
      "[' Every year you have to write up your farm plan. How much money are you going to make for the next five years as a farmer? And the answer is, well, who knows? Is it going to rain? Is it going to flood? What is it going to do, and what are you going to do']\n",
      "Elapsed inf2: 1.994084119796753\n",
      "[\" with all these pieces of paper, putting them in a filing cabinet and all of the work I've done to create that, what happens with it? Probably absolutely nothing. It just sits there doing nothing. My farm plan and everybody's farm plan are\"]\n",
      "Elapsed inf2: 1.904595136642456\n",
      "[\" founding fathers of the United States farm plan was straightforward. We intend to not starve to death. So we're going to make enough food to eat. Is yellow my time's up or is it a warning? I've got two more\"]\n",
      "Elapsed inf2: 1.845810890197754\n",
      "[\" 15 more seconds, that's a lot. Well, that's my farm plan. I don't want to starve and I want to get rid of the paperwork that I have to turn in that proves it. Thank you.\"]\n",
      "Elapsed inf2: 1.8156237602233887\n",
      "[' With the Farm Apprenticeship Mentoring Program, I would like to see the benefit not only in growing a new base of farmers, but also in sustaining and growing the farmland that we utilize to apprentice these farmers']\n",
      "Elapsed inf2: 1.9343008995056152\n",
      "[\" provide back to the program and to the community, not only the food that we all like to eat, but that workforce that will be knowledgeable, will have hands in the aina, no matter where they're at, and will know specifically\"]\n",
      "Elapsed inf2: 0.7436673641204834\n",
      "[' types of things that we need here.']\n",
      "Elapsed inf2: 1.862260103225708\n",
      "[\" and be able to take that forth. And I'd like to see further that there are supports after this mentorship program so that we can continue to support those young farmers until they get to a point where they can actually begin to pay\"]\n",
      "Elapsed inf2: 2.124476432800293\n",
      "[\" back into the program because I always want to see a pay it forward but remembering where they've come from because if we can build that base there and maintain that strong foundation then that is one of the first steps to not just self-sustainability for food but food\"]\n",
      "Elapsed inf2: 0.6244988441467285\n",
      "[' Thank you.']\n",
      "Elapsed inf2: 1.3893284797668457\n",
      "[' I think what we need to do is provide those spaces where we can start to look at using material that we have here to grow our own soil']\n",
      "Elapsed inf2: 1.5574283599853516\n",
      "[' farmers, vegetable farmers, those who even farm grain to some extent now that hemp is being talked about as a huge crop to look at, working in a diversified and a inclusive']\n",
      "Elapsed inf2: 1.907444715499878\n",
      "[' manner, I think we really can keep a lot of the waste down from certain industries by utilizing it in other industries. And that all of that together, we can kind of, again, in a pay it forward manner, use the manure']\n",
      "Elapsed inf2: 2.114609718322754\n",
      "[\" that I have is much better seeded and versed in livestock, things with hooves rather than things with roots. But whether you call it manure, which is exactly what it is, or whether you call it garbage, you've got to move it around and put it\"]\n",
      "Elapsed inf2: 1.8512327671051025\n",
      "[' somewhere to do any good with it. In the old days, when I was a young man, garbage was dealt with by collecting it and the hog farmers would gladly take it. And if you paid them to pick it up,']\n",
      "Elapsed inf2: 1.8505728244781494\n",
      "[\" and then they fed it to their pigs, and then they sold their pigs, they could make money on both ends of the transaction and it would work. It doesn't work that way anymore. The economics of raising livestock that way\"]\n",
      "Elapsed inf2: 2.0881006717681885\n",
      "[\" are not there. How are you going to move your garbage around? Is it going to have stake bones in it? Is it going to have napkins in it? How are you going to process it and handle it and make it make sense? I'd sure love\"]\n",
      "Elapsed inf2: 2.140014886856079\n",
      "[\" like to know. You don't run around cow pastures picking up cow pies to use for fertilizer. You go to places where there are a lot of livestock, be it horses or cows, and you get a lot of manure one time in order to use it for\"]\n",
      "Elapsed inf2: 1.755669116973877\n",
      "[' for the consumers. Meanwhile, we have 20,000 tons of food waste at the Maui County dump, and this could be a valuable indigenous composting material. So Alan, what plans do you have?']\n",
      "Elapsed inf2: 1.6637153625488281\n",
      "[\" to treat that food to become compost for our farmers? Well, my immediate plan is to run for county council so that I won't have to spend as much time moving manure and garbage around\"]\n",
      "Elapsed inf2: 2.058419704437256\n",
      "[\" make that work. We'd love to change our garbage into energy, into something useful, but at what scale are you going to do it and are you going to make it economically viable? I'm best skilled at listening. That's what I do.\"]\n",
      "Elapsed inf2: 2.546628952026367\n",
      "[\" We know there are people on council who don't have very good listening skills. They're good people. And I don't mean, yeah, it is fine. Thank you. You see, when that red thing comes up, it means your minute is over. I'm red, green, colorblind. Sorry. Oh.\"]\n",
      "Elapsed inf2: 1.7245712280273438\n",
      "[' to regenerative farming practices when it comes to this type of nutrient recycling center. And I absolutely believe that if we have the supports in place and at a small scale, we can just grow']\n",
      "Elapsed inf2: 1.454233169555664\n",
      "[' Our next subject is food hubs. Our preparatory comment is across the nation, food hubs are becoming solutions for centralizing food processing and distribution.']\n",
      "Elapsed inf2: 1.5406091213226318\n",
      "[' increasing food production capabilities for small farmers by paving the way for reducing farmer costs. Our Hawaii Farmers Union Maui chapters see this as an opportunity for creating']\n",
      "Elapsed inf2: 1.565464735031128\n",
      "[' farm cooperatives. Further, Hawaii Farmers Union Five Point Program is working with the statewide Farm to School Initiative for growing food for the DOE School Lunch Program.']\n",
      "Elapsed inf2: 1.6640069484710693\n",
      "[' would you prioritize it as a bill or appropriation that you would stand behind, introduce, and or vote for? If yes, please describe benefits you can imagine for the citizens of']\n",
      "Elapsed inf2: 1.9113714694976807\n",
      "[' healthy food financing initiative that you can find at healthyfoodaccess.org. There is the access, the food access portal, which also details quite a few funding sources. I believe that a food hub here not only can']\n",
      "Elapsed inf2: 2.120283603668213\n",
      "[\" aggregate product coming in and we need to help our farmers think about their growing a product because when we look at it, everything is value added. It's not a tomato, it's salsa, it's a sauce. These are the kinds of ways that we need\"]\n",
      "Elapsed inf2: 2.255248546600342\n",
      "[' to get people thinking about the food that is grown here. And I believe that with a food hub, not only can we educate farmers, but we can educate the public. We can have agritourism where we can have people going out and getting more in touch with their food because']\n",
      "Elapsed inf2: 2.4804792404174805\n",
      "[\" That's the issue here at hand today. We are not in touch with our food. We do not know where it comes from. Most of it is packaged and we do not know what's included in it. And I think that's the crux of our getting ill and we need to take that back for our own health.\"]\n",
      "Elapsed inf2: 1.9482805728912354\n",
      "[\" said is that at food hubs you want to have a commercial kitchen. You give me a big affirmative on that? We need a commercial kitchen. One of the things I like to give to people when I'm sitting up in front of you and\"]\n",
      "Elapsed inf2: 1.7765858173370361\n",
      "[\" talking with you or to you, camera over there, is something very practical. We're in a world of limited resources. There's only so much that can get done. One of the most difficult things that\"]\n",
      "Elapsed inf2: 2.437577486038208\n",
      "[\" council members have to do is say, here's the pie, I'm sorry, you're not gonna get a piece. You're deserving, you should have it. Women helping women, I'm all for it. But there's not enough to go. How are we gonna do it? I've got 15 seconds.\"]\n",
      "Elapsed inf2: 1.5348565578460693\n",
      "[' suggest is looking at putting those needed commercial kitchens into our community centers because we already have a location we already have a structure and we already have some degree of kitchen thank you']\n",
      "Elapsed inf2: 1.805082082748413\n",
      "[\" able to house a workforce, especially if they are involved in an apprenticeship program or if they're involved in more community jobs. I think that's a very important thing to have in order. And that changes through zoning.\"]\n",
      "Elapsed inf2: 2.193877935409546\n",
      "[\" pay for imported amendments and inputs, irrigation costs. In other words, it's a lot of expense if you're going to be a farmer. What do you think it will take to make farming a more successful enterprise? And what could you do about that if you were elected?\"]\n",
      "Elapsed inf2: 2.107548952102661\n",
      "[\" Well, the first thing is who's going to be a farmer? We could simplify it a lot if we would just take the definition of a farmer and say it's anybody who files a Schedule F on their federal tax return. People get bogged down in\"]\n",
      "Elapsed inf2: 2.2868099212646484\n",
      "[\" conversations about how much money you have to make to be a farmer. Well, there's no guarantee that when you take up the mantle of being a farmer that you're going to make any money at all. And then if you do give it a number, you must make $10,000\"]\n",
      "Elapsed inf2: 1.8111822605133057\n",
      "[\" thousand dollars to be a farmer people will gain the system I've got a ten thousand dollar go I'm gonna sell you for your ten thousand dollar lemon so let's not spend a lot of time making it more complicated\"]\n",
      "Elapsed inf2: 2.226316452026367\n",
      "[\" sleeping already. The old mats and containers are located all over this island on farmland and that's where your woofers sleep and sleeping hammocks is where they sleep. But I close my eyes and squint because I don't want to see stuff that I might have to tell\"]\n",
      "Elapsed inf2: 2.1788055896759033\n",
      "[\" somebody about. But the farmers, the entrepreneurs are doing what they need to do to be able to get by and get the job done. Thank you. And that's why my time is up. Well, I think you've made your point. You've made a good point.\"]\n",
      "Elapsed inf2: 1.6521685123443604\n",
      "[' The Prefatory comment, BF70 was a near disaster for farmers and ranchers that lease or own large properties. We need these lands protected from ever being seen at their market value.']\n",
      "Elapsed inf2: 1.5939743518829346\n",
      "[' same question. What would you propose for getting lower tax rates on agricultural lands where real farming and ranching is happening? And part two to this question is that assuming you will be on']\n",
      "Elapsed inf2: 1.6232492923736572\n",
      "[\" the budget and finance committee where the budget you would look for other tax revenue to make up for lowering taxes for leased real farm and ranch land. I'm sorry that's so much.\"]\n",
      "Elapsed inf2: 2.2975881099700928\n",
      "[\" since it was first proposed, the first time, and we were able to get it voted down. And the second time, it looked like we had the votes figured out. I didn't show up because I knew we had the votes figured out. It got voted down. And then I went down.\"]\n",
      "Elapsed inf2: 1.799060344696045\n",
      "[' third time bringing with me, no, the first time I got some of my clients to come along, including one who just had a knee replacement surgery. The third time I think I had had my knee replacement surgery.']\n",
      "Elapsed inf2: 1.3000171184539795\n",
      "[' Agriculture is subsidized over this entire planet. The larger the agricultural operation, the more subsidy there is. The small rancher and farmer']\n",
      "Elapsed inf2: 1.802354335784912\n",
      "[\" and that's who's here in the audience tonight, gets the least subsidy, and you're the ones using your sweat equity and the dollars out of your pockets from your second or third jobs to support your agricultural habit.\"]\n",
      "Elapsed inf2: 1.5369555950164795\n",
      "[' So what can we do? Well, I got tired of going to the seventh floor of the county building to give testimony. I got tired of looking at my clients sitting there']\n",
      "Elapsed inf2: 1.6949152946472168\n",
      "[' looking at the backs of the council people, except for the chair sitting way up high above everybody else, and I decided at one point in a very weak moment to try and do something about it.']\n",
      "Elapsed inf2: 1.130293607711792\n",
      "[' until the people who sit on the council have experience in agriculture and listen to us. Thank you.']\n",
      "Elapsed inf2: 1.708738088607788\n",
      "[' Where in the budget, ah, missed a word. Excuse me. Where in the budget would you look for other tax revenue to make up for lowering taxes for leased real farm and ranch land?']\n",
      "Elapsed inf2: 1.8505609035491943\n",
      "[' count farmers. It did not include people who are actively farming and that was the wrong thing to do. When we look at what we can do to support our farmers, I think we need to look at ag conservation easement.']\n",
      "Elapsed inf2: 1.6240954399108887\n",
      "[\" where those farmers that agree and that promise that this is what they're going to do is grow food, that we allow them these conservation easements to help ease the burden of taxes on those\"]\n",
      "Elapsed inf2: 1.5707485675811768\n",
      "[' specific properties, whether or not they decide to build other dwellings on it to house themselves or their family or their workers. I think that we very critically need to look at more']\n",
      "Elapsed inf2: 1.5539462566375732\n",
      "[' taxes for leased farmland, real farm and ranch land? Absolutely look at where the visitor industry gets its funding from. I would take from the visitor industry funding first.']\n",
      "Elapsed inf2: 2.083927869796753\n",
      "[' because we seem to have this, or members of the council seem to have this idea that that industry needs to be funded above all else. And while that does bring money into our economy, we cannot eat from it. We need to eat from our aina.']\n",
      "Elapsed inf2: 1.0008537769317627\n",
      "[' believe and I absolutely would on the budget committee look at that funding first.']\n",
      "Elapsed inf2: 2.0578861236572266\n",
      "[' Thank you. Well, on the subject of eating, food security and self-sufficiency, Trinette, could you in one minute tell us if barges of food stopped coming to Maui from the mainland tomorrow, how you would propose to']\n",
      "Elapsed inf2: 1.627091884613037\n",
      "[\" to organize our food security for such a catastrophe? Easy question, huh? Absolutely not an easy question because to me, and I've looked up the definition of food security,\"]\n",
      "Elapsed inf2: 2.0982890129089355\n",
      "[' What that means is the access and availability of food for all, regardless of whether or not you are economically advantaged or disadvantaged. Now Maui County itself, given if we were cut off from supplies by the barge right now, we do not have']\n",
      "Elapsed inf2: 2.0949230194091797\n",
      "[\" enough food to last us out the week. We definitely don't. And furthermore, those who are at a better economic advantage than others will end up getting that food. There's no doubt about it. You know, supply drives and demand drives the\"]\n",
      "Elapsed inf2: 2.0807106494903564\n",
      "[' market. What we need to do and what I would like to do and hope is to support those small farmers, those that are going to our farmers markets now and allow them the tech that they need, the manpower, the equipment, whether']\n",
      "Elapsed inf2: 1.9548835754394531\n",
      "[' comes from county sources or not to help pull out that food, harvest what we need and make it a community thing because if we all share, we are in an island, it is a Kako thing, we can get through it.']\n",
      "Elapsed inf2: 1.904512643814087\n",
      "[' Alan, your one minute question is about buying and eating locally. If the price of local food is unattainable for the average resident, how can the county partner with its farmers to ensure that they get what they need to make a']\n",
      "Elapsed inf2: 1.8551995754241943\n",
      "[\" one minute. What I can say is that you've got to have food available if you're going to eat. I've got a bunch of goats. If you want some goat milk or some goat meat, I can make that\"]\n",
      "Elapsed inf2: 1.7973887920379639\n",
      "[' happen. You want to go to a barter system, we can all make that happen. But if you really want food security, the part of it that is most interesting to me is making sure we keep out the']\n",
      "Elapsed inf2: 1.889936923980713\n",
      "[' ranchers throughout the state, it started eating more sugar cane. Well, sugar cane went belly up because of economics. The real amazing thing is that this plantation stayed alive for 30, 40 years longer than the plantations on the other']\n",
      "Elapsed inf2: 1.4747581481933594\n",
      "[' collective of members who protect the interests of our family farmers from any practice that contaminates, commodifies, or compromises their ability to farm and market their products.']\n",
      "Elapsed inf2: 1.616163730621338\n",
      "[\" currently employed practices we don't support? And I would say that don't work. In one minute, and starting with Dr. Kaufman, what would you do to empower the Hawaii Department\"]\n",
      "Elapsed inf2: 1.3019592761993408\n",
      "[' Agriculture and the Hawaii Department of Health by supporting bills that monitor pesticide drift to protect our health and environment such as product testing, soil']\n",
      "Elapsed inf2: 1.600379467010498\n",
      "[' I want to take part of that question and say, as a veterinarian, I deal with chemicals all day long. The wonderful thing about many of the chemicals that I deal with']\n",
      "Elapsed inf2: 2.480255126953125\n",
      "[\" I'm a drug dealer. They're drugs. They're medicines. What are you going to call these things? And the words we use to describe things that can be helpful to maintaining the health of our pets, there's a little dog over there. Have you got him on heartworm preventative? It's one of the\"]\n",
      "Elapsed inf2: 1.8220319747924805\n",
      "[\" empowered, it's just making them accountable. They are not working within the parameters that are already there for just the basic supports, for just the basic regulations. And I think what needs to happen first is to get them to\"]\n",
      "Elapsed inf2: 1.4744291305541992\n",
      "[' over cane burning and just the absolute attitude with which many in that department and I may say even in the Department of Ag have towards the people bringing up very valid concerns']\n",
      "Elapsed inf2: 1.853912353515625\n",
      "[\" disgusting and so it's not about empowering them they already have a modicum of power it's about holding them accountable and responsible for not using that power and for enforcing rules for us for our benefit and the benefit of our\"]\n",
      "Elapsed inf2: 0.6569042205810547\n",
      "[' children. Thank you.']\n",
      "Elapsed inf2: 1.8589563369750977\n",
      "[\" to make it profitable. How are we gonna grow any product on an economy of scale that will be profitable? I don't know. At this point, we don't even know if there will be water in the Central Valley.\"]\n",
      "Elapsed inf2: 1.8294596672058105\n",
      "[\" For the next three years, it wasn't 13 years as was misstated earlier, for the next three years, there's gonna be water coming through EMI. After that, the Supreme Court will rule or maybe sometime\"]\n",
      "Elapsed inf2: 1.9457964897155762\n",
      "[\" during the three years, it'll rule, where is the water gonna go? It is a public trust. So it would be reasonable to suppose some of it would go back in the ocean for the environment, some of it for people on the\"]\n",
      "Elapsed inf2: 1.8005530834197998\n",
      "[\" closing presents for us with this particular crop first offers us an opportunity to remediate the soil because we need to do that quickly before we can actually start growing viable food, I believe, that we'll feed ourselves.\"]\n",
      "Elapsed inf2: 1.4478490352630615\n",
      "[\" I do want to support farmers that commit to growing hemp as a remediative purpose and indeed identifying parcels for them to do that. We don't have\"]\n",
      "Elapsed inf2: 2.005079746246338\n",
      "[' and they do have a history of working with it. And so perhaps we can have people sent there and have them come to us. I mean, it is very possible to have partnerships outside of the United States, as we have in the past before.']\n",
      "Elapsed inf2: 1.7421438694000244\n",
      "[' work here. So do you have concluding remarks about your position on agriculture and or is there a question you wanted to be asked and you want to answer? My concluding remarks. I like to eat.']\n",
      "Elapsed inf2: 1.623161792755127\n",
      "[\" I'm not a farmer. I raise chickens for fresh eggs, but I do see the benefit in just that small scale farming of sorts for myself and my family. The benefits of eating something\"]\n",
      "Elapsed inf2: 1.8867511749267578\n",
      "[\" that I know exactly where it comes from and I know what it's been fed. And it's huge, it's beyond physical sustenance. It connects us to our aina. And so I very much support agriculture and supporting\"]\n",
      "Elapsed inf2: 1.9849436283111572\n",
      "[' ourselves and the people who call Maui home, who live here, who grow here, and I mean grow their families, grow our food, who lay their bones to rest here, because it is all of us. It is not those investments.']\n",
      "Elapsed inf2: 1.214686393737793\n",
      "[' continue to support that in any way possible. So thank you. Thank you. Alan, your concluding remarks.']\n",
      "Elapsed inf2: 1.5699443817138672\n",
      "[' Between us, we have a total of five children under the roof. And the wonderful thing about this family is that it includes blood of Chinese, Hawaiian, Puerto Rican,']\n",
      "Elapsed inf2: 0.713320255279541\n",
      "[' those children. Thank you.']\n",
      "Elapsed inf2: 1.865382432937622\n",
      "[\" So if we would start out, why don't we start out with you, Tiger? Do you want to just take a minute to introduce yourself to our audience here and in our viewing public? One minute. One minute.\"]\n",
      "Elapsed inf2: 2.233466148376465\n",
      "[\" initiative that everybody has taken to understand what's happening on this island. And that's, it's a very odd thing. It's a paradigm that's happening. And I, and we're just really lucky to have the opportunity. I'm, I'm really stand for being a local\"]\n",
      "Elapsed inf2: 2.309898614883423\n",
      "[\" We've done a lot of agricultural demonstration, biofield crop demonstration over the last five years. I've become very immersed in how to get those kinds of things funded at the state and federal level. And I've got expertise in a lot of the issues that have been talked about today, so I'm\"]\n",
      "Elapsed inf2: 2.278127670288086\n",
      "[\" really looking forward to these questions. Mahalo. Thank you so much. I'm going to point out before I turn this over to Mike that we have four people running on your ballot. We have two of them here tonight. So thank you very much for being with us here tonight.\"]\n",
      "Elapsed inf2: 1.7516789436340332\n",
      "[' Hawaii Department of Agriculture funded pilot nutrient cycling composting center on Maui. And what do you see, and what do you see any, and do you see any barriers that are currently in the way of']\n",
      "Elapsed inf2: 1.5914790630340576\n",
      "[\" getting nutrient cycling underway and what can you do to help alleviate those barriers? Do you need me to repeat that? There's a misprint here and I stumbled over it.\"]\n",
      "Elapsed inf2: 1.5862390995025635\n",
      "[' county management and the importance of having a county manager that would work together with the council because the council needs to be working with the administration on these initiatives, not against it.']\n",
      "Elapsed inf2: 2.788377523422241\n",
      "[\" composting with my grandfather since I've been three or four. He always had a big bucket near the boathouse where we put the fish stuff, we put all the stuff we carved up from the vegetables in the garden, and then he made sure that he would mix it with a little bit of grass from we cut from the lawn, and we put it back in the\"]\n",
      "Elapsed inf2: 1.8483753204345703\n",
      "[' supports the concept of farmers living on the land they farm and the land they lease through an agricultural land trust. What ideas would you propose in moving this direction so that it can be actualized that people can live on their']\n",
      "Elapsed inf2: 2.431246042251587\n",
      "[\" I know at the university right now, we've got 300 students in the process. We just graduated 50, and there's another 100 right behind them. So we don't have this big army of farmers ready to take on, but we're starting to prepare. Myself being in the private sector and business field,\"]\n",
      "Elapsed inf2: 2.2984631061553955\n",
      "[\" move in this direction and what would you propose so that it can really happen? Well, thank you, Lucienne. There's actually already a movement to make that happen and my friend Dale Boner has been working on that. He was the former head of the Maui Coastal Land\"]\n",
      "Elapsed inf2: 2.1516449451446533\n",
      "[' organic ag park. Do you have any idea what became of this? And do you think we should continue to pursue this concept in the next county budget session? Well, I do think that we need to continue to pursue it. Maybe not with that particular piece of property. I']\n",
      "Elapsed inf2: 2.4705827236175537\n",
      "[\" and I see this as somebody who worked for six years trying to get a biofuel production tax credit passed. I made it up to the fifth year, got it passed, didn't get it signed by the governor. This year we actually got it passed and signed. So it does take a lot of work to get it.\"]\n",
      "Elapsed inf2: 1.996779441833496\n",
      "[' collective work it takes a lot of people coming forward and explaining why this is so important I think it can happen I think it needs a bigger voice and I think it needs an advocate from the County Council at the state legislature I have a lot of experience working']\n",
      "Elapsed inf2: 1.631488561630249\n",
      "[' have been used to dispose of personally filtered sewage water. The county lost the lawsuit citing violations to the Clean Water Act and faces potentially millions in fines and has spent 2.25 million on']\n",
      "Elapsed inf2: 1.5127110481262207\n",
      "[\" For both of you, you'll have one minute. What will you do to initiate a citizen's task force and request proposals for the state of the art treatment plants\"]\n",
      "Elapsed inf2: 0.7446985244750977\n",
      "[' for state of the art treatment plants']\n",
      "Elapsed inf2: 2.084833860397339\n",
      "[\" so we can end the use of injection wells that are harming the ocean environment? Well that's a great question because it's already happening. There's already a citizens task force that has started working on this. I went to a day long workshop back in May\"]\n",
      "Elapsed inf2: 2.0525057315826416\n",
      "[\" areas are the worst, even though La Jena gets all the attention because of the lawsuit. But that is turning into a citizen's task force and I would support that going forward. We looked at various kinds of technologies and we ascertained that that's the\"]\n",
      "Elapsed inf2: 1.8226730823516846\n",
      "[\" And you'll each have kind of a separate question here, a one minute question. So the Farmers Union is a solution-based, action-oriented collective of members who protect the interests of our family farmers from any practice\"]\n",
      "Elapsed inf2: 1.7353293895721436\n",
      "[\" contaminates, commodifies, or compromises their ability to farm and market their products. So truth in advertising, that's what the Farmers Union stands for. They're actively involved in proving the efficacy of\"]\n",
      "Elapsed inf2: 1.7615363597869873\n",
      "[\" organic and regenerative practices for field practice and economic efficiencies. And the idea is to replace currently employed practices that the union, the Farmers Union does not support. So we'll start with you this time,\"]\n",
      "Elapsed inf2: 1.5895040035247803\n",
      "[' as well as human health, bees, and the environment. So would you initiate and support a county pilot program such as a testing for bee pollen and honey to monitor pesticide drift?']\n",
      "Elapsed inf2: 1.6777410507202148\n",
      "[\" people and the environment would you be willing to support the biological applications if yes share why and how you would support moving in this direction if no give your reason why I'm not I'm not in favor\"]\n",
      "Elapsed inf2: 2.405839681625366\n",
      "[' because there are some real concerns about invasiveness, about cross pollination and some other things like that. So we need to get together and open up the discussion, talk about those things as well as the benefits, talk about who wants to grow. The DOA is actually doing a survey right now to find out who']\n",
      "Elapsed inf2: 1.8233578205108643\n",
      "[\" you to wrap things up and you have one minute each to offer any concluding remarks about your positions on agriculture or if there's a question that you would have liked to answer but it didn't get asked you can ask your\"]\n",
      "Elapsed inf2: 1.791346788406372\n",
      "[\" candidates. South Maui, consul seat. Remember, there are four candidates on the ballot. We're only seeing two tonight, so keep that in mind. Very good job. Thank you very much, candidates.\"]\n",
      "Elapsed inf2: 2.212061643600464\n",
      "[\" blessed tonight and thank you for staying this long into our presentation. We're going to start off with giving each of you a one minute chance to introduce yourself, tell the voters a little bit about where you are. And I'm going to start with Mr. Cunney at the end\"]\n",
      "Elapsed inf2: 1.8655920028686523\n",
      "[' with a degree in education and eventually started being a teacher at Maui High School. Prior to doing that, I got into the private sector and had some experience in that sector of trying to survive and make a living and start']\n",
      "Elapsed inf2: 1.5364673137664795\n",
      "[\" current at the height I was growing probably 14,000 pounds in 2011 of apple bananas and so I'm like many of you put my hand into the into the dirt and\"]\n",
      "Elapsed inf2: 1.3279991149902344\n",
      "[' on the office that we are all trying to serve. And so with that, I look forward to the conversation this evening, thank you.']\n",
      "Elapsed inf2: 1.441889762878418\n",
      "[' agriculture, and most importantly, food. And it is a critical point here on this island and with interest I have in the production of food. Thank you.']\n",
      "Elapsed inf2: 1.2670834064483643\n",
      "[' have created thousands and thousands and thousands of tons of good soil amendment, class A, EPA approved for use on fruits and vegetables.']\n",
      "Elapsed inf2: 1.8754215240478516\n",
      "[\" was my opening act. So I'm very, very happy to be here among the farmers. I grew up in farm country in Montana. Can you conclude because we're at our one minute here. That's what the red means.\"]\n",
      "Elapsed inf2: 2.1120996475219727\n",
      "[' Aloha, Joe Blackburn. I want to take you back in time. Just got promoted to the hazardous materials captain at the Maui Fire Department. Took an oath to protect life and environment. But very lucky, got sent away to the top training in the nation.']\n",
      "Elapsed inf2: 2.5000619888305664\n",
      "[\" the one I'm most proud of is I went to Yale school one day and a teacher handed me a box full of chemicals and she said, can you take them? And I said, well, the fire department doesn't allow us to take them. And I looked at the bottles. Some looked like they had pick, rake,\"]\n",
      "Elapsed inf2: 1.6158533096313477\n",
      "[\" some of the firefighters still look at me and say, Cap, you shouldn't have done that because it affected your career. But I did. Thank you. Thank you.\"]\n",
      "Elapsed inf2: 2.405869960784912\n",
      "[\" So in case we didn't explain before, we have a lovely timekeeper and when you see the yellow, you have 15 seconds left and the red means, oops, one minute, we're there. So our first question's on the workforce development. You've probably heard this a few times.\"]\n",
      "Elapsed inf2: 1.9242260456085205\n",
      "[' times this evening, but our farmers are aging and we all agree we need to grow a new generation of farmers and they need to be equipped with the skills to be really successful at their farming enterprises. So the Farmers Union']\n",
      "Elapsed inf2: 2.128336191177368\n",
      "[\" has a farm apprentice mentoring program, FAM, and it's about to begin its third year with county funding. So the question is, and we're going to start with Alika this time, if the Farmers Union were to come to the budget and\"]\n",
      "Elapsed inf2: 1.8733975887298584\n",
      "[' Finance Committee at the console asking that our FAM program be permanent line item in the budget. And in order to demonstrate that the county has ongoing support for growing our next generation of farmers, what issues would you']\n",
      "Elapsed inf2: 2.080096960067749\n",
      "[\" want to have raised before making such a decision? In other words, what would you want to know before making such a decision? So starting with Aliko, one minute. I really would not have no issue because, you know, it's it's a\"]\n",
      "Elapsed inf2: 1.6910185813903809\n",
      "[' The demand that we have that is real right now on our island, we need to invest in our future and we need to invest in our farmers and farm education so that we can have people on']\n",
      "Elapsed inf2: 1.7762749195098877\n",
      "[' is only 0.4%. Not even, or is it less now? But not even a half of a percent is invested in agriculture. And in that arena of agriculture, how much of that is financed']\n",
      "Elapsed inf2: 2.1355302333831787\n",
      "[' Do you need the question repeated or can you remember from when we gave it? Basically, if this came to the Budget Committee, would you support it and would you support it being a line item every year and what would you need to know in order to make that decision?']\n",
      "Elapsed inf2: 1.744663953781128\n",
      "[\" Okay, I would definitely support it. I'm all in favor of bringing forth a new generation of farmers. And what I would need to know is all the data that my council people, my colleagues,\"]\n",
      "Elapsed inf2: 1.6341650485992432\n",
      "[\" So that's what I would be looking for. How can we make sure that this gets through? And I would need to have all the information possible in order to create a really good\"]\n",
      "Elapsed inf2: 1.8991389274597168\n",
      "[\" breakdown of costs. What are the administrative costs? How many people are being benefited? How is it going to carry on? We know it's important, but everybody who comes before the council has their own story and their own tale\"]\n",
      "Elapsed inf2: 1.7125766277313232\n",
      "[' amount of money and an unlimited amount of requests. So basically, I would sit down and even help you look at how you can tailor your presentation to make it palatable to the powers that be because']\n",
      "Elapsed inf2: 1.9982938766479492\n",
      "[\" So I think what Joe said is very important. You need to make sure that you have a performance of a project, in this case for a fund, you need to make sure that it's performing. And if it is performing, then you can start\"]\n",
      "Elapsed inf2: 1.7661049365997314\n",
      "[\" discussing holding on or if it's doing above what performance it was presented with and you can get expanded funds. As far as permanent funds, that's why we have other funds that got dedicated funds and that was passed\"]\n",
      "Elapsed inf2: 2.1207199096679688\n",
      "[' by ordinance and so this is something that would have a potential to get a dedicated permanent fund. But that again, you gotta go through steps to do that. I know earlier Ms. King from South Maui as a candidate talked about how long it took for her to get']\n",
      "Elapsed inf2: 2.057075023651123\n",
      "[\" project here was to build Eco Compost, but I didn't do that alone. I had a team of people. I had Tim Gunter from this community standing right there with me saying, yes, there is a market for this stuff. We need this.\"]\n",
      "Elapsed inf2: 2.2091259956359863\n",
      "[\" I did fall down because I take the grass and I put it into my taro as mulch. And how you fall off a lawnmower, you're going to have to ask my wife about that. But I love the thought. I'd like to know more about it.\"]\n",
      "Elapsed inf2: 1.7750670909881592\n",
      "[\" initiating something within our own agricultural subdivision to do compost hub and something that we have there. We're already generating, I think, tens of thousands of pounds of food out of that subdivision every year.\"]\n",
      "Elapsed inf2: 2.15934157371521\n",
      "[\" every year. And I think we have the capacity to start doing something there. One of our challenges would be we have a property there that's supposed to be dedicated for the park. We may go to the county council and ask them to consider waiving the park and instead\"]\n",
      "Elapsed inf2: 1.7395517826080322\n",
      "[\" No, no, I'm good. One of the situations we have is our recycling program has really gone downhill. What we'd rather do is recycle from the site instead of trying to separate somewhere else.\"]\n",
      "Elapsed inf2: 2.321608781814575\n",
      "[\" else. And so the idea would be somehow to get that food waste, and I'm not sure how the process would work, into the hands of the people who could use it. My example, and it's pretty crude though, is the pig farmers who go around to the restaurants and pick up all the\"]\n",
      "Elapsed inf2: 2.147247791290283\n",
      "[\" food waste. Well, there's not enough pig farmers for the food waste. So how we would do that, I'm not sure, but I would like to see a recycling program that includes food waste because that's nutrients that can go back into the soil and the land.\"]\n",
      "Elapsed inf2: 1.8793156147003174\n",
      "[' of getting nutrient cycling underway? And what can you do to help alleviate those barriers? May we start with Dane, please? Forgive me, Mike, if you will, please, if you can repeat the question, I apologize.']\n",
      "Elapsed inf2: 1.7384777069091797\n",
      "[' barriers that you would see that are kind of in the way now of getting something like this underway to have a nutrient cycling center and what could you do to help kind of get those barriers out of the way?']\n",
      "Elapsed inf2: 2.5227580070495605\n",
      "[\" THIS IS FOR EACH OF DAIN, ALIKA AND HANNAH. EACH OF YOU HAVE ONE MINUTE TO ADDRESS THE SAME QUESTION. YOU GOT A SEPARATE QUESTION. THANK YOU. STATE DEPARTMENT OF AG, SO AGAIN, WE'RE RUNNING FOR THE\"]\n",
      "Elapsed inf2: 1.7684767246246338\n",
      "[\" County Council so a little bit difficult for us to have the jurisdictional authority over that so I want to say that first and foremost obviously it would be a good idea because it's a step in the right direction I\"]\n",
      "Elapsed inf2: 2.3232109546661377\n",
      "[\" I think everybody in this room agrees that what we're talking about, the subject matter is, I think we're all raising our hand and saying yes, this is good stuff that we're talking about. But from the context of what can we do as council members, I think that's what's important.\"]\n",
      "Elapsed inf2: 1.88525390625\n",
      "[\" When we, I think we need to start looking at sites, available land, if the county has existing land that they could provide to work with the state on the pilot program. If it's not state land, if the county can\"]\n",
      "Elapsed inf2: 2.1488454341888428\n",
      "[' come up with something and partner with the state on some of these pilot projects. If we see some success to it, then now the county has more of a leg to stand on in supporting these things beyond a pilot project. But again, we need to stay within the context of']\n",
      "Elapsed inf2: 1.5330324172973633\n",
      "[\" what we have control over and authority over. And so that's my response to the State Department of Ag question on a pilot program. Yes, but what can we do?\"]\n",
      "Elapsed inf2: 2.029597043991089\n",
      "[\" Yeah, I would deal with what danger shared it is it the funding is coming from the State Department of Agriculture, and this is a project, however, my understanding, I think it was targeted for something like a million dollars I think it's too little.\"]\n",
      "Elapsed inf2: 1.2319180965423584\n",
      "[' So I think we need to be a part and a partner in this with the state and moving forward. Thank you.']\n",
      "Elapsed inf2: 1.9428026676177979\n",
      "[' Okay, there is an EPA hierarchy for food waste and for food. First, people. The second is animal food, all right? The third is composting. And then we go to any type of energy, and then we go to']\n",
      "Elapsed inf2: 2.558072090148926\n",
      "[' THE LANDFILL. THAT IS THE HIERARCHY. NOW, I HAVE BEEN INVOLVED IN RECYCLING FOR A LONG TIME, GUYS, AND WE HAVE FUNDED PIG FARMS, EVEN JUST THIS LAST YEAR WHEN I WAS NOT AT']\n",
      "Elapsed inf2: 1.7631511688232422\n",
      "[\" Because if you intend on selling that compost, you have a big wad of environmental red tape to cut through. But I am the red tape specialist. Thank you. This is from the horse's\"]\n",
      "Elapsed inf2: 1.8815417289733887\n",
      "[' So across the nation, these are becoming solutions for centralized food processing, distribution, et cetera, et cetera. Our farmers union chapters see this as a great opportunity for creating farm cooperatives, and we also see it']\n",
      "Elapsed inf2: 2.104088068008423\n",
      "[\" as a way to make sure that we have enough food for this program for the Department of Education to buy food for our farmers. So our question, to get down to the question, I'm not reading the whole intro, I'm summarizing obviously.\"]\n",
      "Elapsed inf2: 1.908402681350708\n",
      "[\" funds. In other words, get some county funds, the state would throw in something and there'd be some matching for federal funds. Would you make this a priority bill or appropriation that you would stand behind, introduce,\"]\n",
      "Elapsed inf2: 2.1563870906829834\n",
      "[\" farmers union are the people who want this to happen. So you'd have to put together the package, make it make sense, and then I would push it forward from my end of the situation. Talked a long time ago about I always supported organic farming.\"]\n",
      "Elapsed inf2: 2.470015525817871\n",
      "[\" farms. How we do it, where we do it, where we get the water, again, are going to be the key issues in what we're going to grow. Thank you. Great. Dane, you want to jump on that? Do you need any repeating? No. Okay, thanks. I'm going to\"]\n",
      "Elapsed inf2: 1.5561926364898682\n",
      "[\" of your peers and your colleagues who have different mindsets and convincing them of the benefit of this type of thing. I'll give you an example just to give you an idea.\"]\n",
      "Elapsed inf2: 1.7308812141418457\n",
      "[' Even if you have advocates for something, and I see Susan Bradford here, a completely different subject matter. We want to preserve several properties in front of a beach, and you have advocates that support that.']\n",
      "Elapsed inf2: 1.645876169204712\n",
      "[' somebody who goes and champions it and then at the very end because of other things that are going on money availability of limited fund or lack of availability of funds people change their mind and they compromise it']\n",
      "Elapsed inf2: 2.0850772857666016\n",
      "[\" And so they're not able to get everything that they wanted to get. The bottom line is there's a lot of navigating through the system based on what Joe just said, you got to navigate it through. Thank you. Alika, your question, one minute.\"]\n",
      "Elapsed inf2: 1.647904634475708\n",
      "[' is tourism and we need to look at other opportunities of economic development. I strongly believe that answer will come to us in the form of food production. But to get food production and agriculture up to']\n",
      "Elapsed inf2: 1.8245155811309814\n",
      "[\" We need a lot of the farmers from the farm apprentice side growing. We need the level of food production at that level to where we now have merits for a processing center. And that's where the food hub comes in.\"]\n",
      "Elapsed inf2: 1.6162779331207275\n",
      "[\" because navigating through the system to get something actually funded that is new, it's not impossible. I know because I've done it for years with recycling, but it takes an awful lot in\"]\n",
      "Elapsed inf2: 1.909087896347046\n",
      "[' sometimes a lot more time than what you would think. So again, I go back to the data, I go back to the business plan, I go back to all of the details that people would want to know if they were responsible for']\n",
      "Elapsed inf2: 1.734095573425293\n",
      "[\" spending public funds and that's what i would need in order to uh you know fully push this forward and that would be like joy said joe said we're as council people we cannot function in a in a\"]\n",
      "Elapsed inf2: 1.533531665802002\n",
      "[' vacuum. We have to have the community support behind pushing this government into new ways of doing things, new ways of doing, of thinking. Thank you. Thank you all.']\n",
      "Elapsed inf2: 1.5902633666992188\n",
      "[\" Our next area is farmland zoning and affordable land trusts. We'll begin with Joe. Our organization supports the concept of farmers living on the land they farm and lease through an agricultural land\"]\n",
      "Elapsed inf2: 1.7947404384613037\n",
      "[' something that could work. But I would start with the USDA and sit down with them as to how they could provide funding so you guys can realize your dreams. Thank you. Thank you. Dane, one minute.']\n",
      "Elapsed inf2: 1.240175485610962\n",
      "[' more options for farm worker dwellings, including temporary structures, such as the new trend of tiny houses and yurts.']\n",
      "Elapsed inf2: 1.7056362628936768\n",
      "[\" I don't have, frankly I don't have the idea of how to make that happen. And again, it comes down to engaging those who have the expertise in those respective fields, whether it's for\"]\n",
      "Elapsed inf2: 1.4466450214385986\n",
      "[' forward with good long-term policy changes. Now, if it deals with changing existing, then we have to look at that. Thank you, Dane.']\n",
      "Elapsed inf2: 1.502934455871582\n",
      "[' farming a more successful enterprise? And what will you do about that if elected? Go back to the future. Okay. So with that, we must learn from our past']\n",
      "Elapsed inf2: 1.909921407699585\n",
      "[\" utilize the USDA system. They give out $300,000 for a farmer. What if we have 10 United Farmers and all of them got that application of 300,000? That's $3 million that they can utilize in their pool\"]\n",
      "Elapsed inf2: 1.8237712383270264\n",
      "[' One of the things that would have to happen is that our building permit process is broken. We have to fix that. We have zoning. We have lots of regulations on what type of housing is permitted and where is the water']\n",
      "Elapsed inf2: 1.7359890937805176\n",
      "[\" That's an issue also if you're gonna be living on the land, where is that water meter for your house and the infrastructure? But at the same time, we have to take a look at things like\"]\n",
      "Elapsed inf2: 1.645817518234253\n",
      "[\" composting toilets, we've got to take a look at catchment water, other ways of actually surviving on the land that people have done for years that we'd have regulated ourselves out in the\"]\n",
      "Elapsed inf2: 0.6849546432495117\n",
      "[' process of becoming a government.']\n",
      "Elapsed inf2: 1.439051866531372\n",
      "[' really wanted to make the point that we need Maui County on board to really support a positive image for the future of agriculture here, not look for more ways']\n",
      "Elapsed inf2: 1.9668984413146973\n",
      "[\" to make money off of it. So your question would be, and this is for each of you, and I guess we'll start with Joe this time because we went in with Hannah. What would you propose for getting lower tax rates on ag loans\"]\n",
      "Elapsed inf2: 1.6459755897521973\n",
      "[\" where real farming and ranching is happening. And part two, assuming you'll be on the budget and finance committee, where would you be looking to make up for what you subsidize Ag-\"]\n",
      "Elapsed inf2: 1.0393662452697754\n",
      "[' land in other tax revenues? Joe. Do I have to go first on this one?']\n",
      "Elapsed inf2: 2.0949618816375732\n",
      "[\" 30 avocado trees, but they're not bearing, and I have a nice house. So I don't know where I would fall in this category. I think we gotta go back to what the planning department has been doing, which is making you do farm plans.\"]\n",
      "Elapsed inf2: 2.0642786026000977\n",
      "[\" and that they would come out and check the farm plan, and if you were following the farm plan, you would get a discounted rate. And they're actually doing that somewhat now, but I discounted a little more. Where you would make up the\"]\n",
      "Elapsed inf2: 1.9322845935821533\n",
      "[\" Boy, that's tough because if you go after probably the lowest tax rate, which is a residential people, you're not gonna get reelected. So I don't know the answer to that part of the question. Thank you.\"]\n",
      "Elapsed inf2: 1.6167254447937012\n",
      "[' Thank you very much. Well, Dane, this hot potato is in your lap here. So I served as the budget and finance chair for two years, in 2005 and 2006.']\n",
      "Elapsed inf2: 2.1746480464935303\n",
      "[\" So not only was I in the middle of it, I was on the chair that had to facilitate this type of discussion. And so, A, Joe touched on it a little bit. When we're looking at ag, we have to make sure that the guys who are\"]\n",
      "Elapsed inf2: 1.9652180671691895\n",
      "[\" claiming an ag classification, that they're doing ag. And if they're not, then they're going to get charged more. The other part of it is, where do we come up with the difference? Probably one of the toughest ones\"]\n",
      "Elapsed inf2: 1.878458023071289\n",
      "[\" higher tax burden, they are also impacting us the most. We still need to look at trimming the additional monies that they use for marketing and instead let them go pay the marketing on their own. So it's not a\"]\n",
      "Elapsed inf2: 1.848259449005127\n",
      "[\" cutting them off completely but I think there needs to be a weaning a weaning of monies towards that for the marketing aspect of our industry to support the additional industries that we want to lift up that's my answer\"]\n",
      "Elapsed inf2: 1.5483171939849854\n",
      "[' 70 proposal that I would incorporate and have that moving forward. And that was the funding of the two or three staffing position to go out and verify if these guys']\n",
      "Elapsed inf2: 1.827183723449707\n",
      "[\" are actually farming so that we can then bring back and collect our tax rate on a true level. It's just, you know, they file the paper. There's no follow through in the taxation collection. So\"]\n",
      "654.2329833507538\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "start_time = time.time()\n",
    "dataset = load_dataset('MLCommons/peoples_speech', \"microset\", split='train', streaming=True)\n",
    "for sample in dataset:\n",
    "    input_features = processor(sample[\"audio\"][\"array\"], sampling_rate=sample[\"audio\"][\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    t = time.time()\n",
    "    y1 = model.generate(input_features)\n",
    "    print(f\"Elapsed inf2: {time.time()-t}\")\n",
    "    t = time.time()\n",
    "    # print(f\"Tokens inf2: {y1}\")\n",
    "    t1 = processor.batch_decode(y1, skip_special_tokens=True)\n",
    "    print(t1)\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bda27f-23cc-4b76-ba4c-109630c883a5",
   "metadata": {},
   "source": [
    "時間: 659.0221, 654.232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2af0556-7b3a-4a8d-8a80-6f69e1bd55ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">json</span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>audio_path = <span style=\"color: #808000; text-decoration-color: #808000\">\"sample_audio.wav\"</span>                                                              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>4 response = predictor.predict(data=audio_path)                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(json.loads(response))                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7 </span>                                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base_predictor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">212</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> inference_component_name:                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>request_args[<span style=\"color: #808000; text-decoration-color: #808000\">\"InferenceComponentName\"</span>] = inference_component_name              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>212 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>response = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**req   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._handle_response(response)                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_handle_response</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, response):                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/botocore/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">570</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_api_call</span>                      <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>py_operation_name<span style=\"color: #808000; text-decoration-color: #808000\">}() only accepts keyword arguments.\"</span>              <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 568 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 569 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The \"self\" in this scope is referring to the BaseClient.</span>                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 570 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._make_api_call(operation_name, kwargs)                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 571 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 572 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>_api_call.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span> = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(py_operation_name)                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 573 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/botocore/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">context.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">124</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> start_as_current_context():                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> hook:                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hook()                                                                 <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>124 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span>                                                                                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/botocore/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1031</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_make_api_call</span>                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1028 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Code\"</span>                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1029 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1030 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>error_class = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.exceptions.from_code(error_code)                           <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1031 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> error_class(parsed_response, operation_name)                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1032 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1033 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> parsed_response                                                        <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1034 </span>                                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModelError: </span>An error occurred <span style=\"font-weight: bold\">(</span>ModelError<span style=\"font-weight: bold\">)</span> when calling the InvokeEndpoint operation: Received server error <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span> \n",
       "from primary with message <span style=\"color: #008700; text-decoration-color: #008700\">\"Your invocation timed out while waiting for a response from container primary. Review </span>\n",
       "<span style=\"color: #008700; text-decoration-color: #008700\">the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\"</span>. See \n",
       "<span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://us-west-2.console.aws.amazon.com/cloudwatch/home?</span><span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">region</span><span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">=</span><span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">us</span><span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">-west-2#logEventViewer:</span><span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">group</span><span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">=/aws/sagemaker/Endpo</span>\n",
       "<span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">ints/pytorch-inference-neuronx-ml-inf2-2025-03-19-11-30-08-598</span> in account <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">392304288222</span> for more information.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mjson\u001b[0m                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m3 \u001b[0maudio_path = \u001b[33m\"\u001b[0m\u001b[33msample_audio.wav\u001b[0m\u001b[33m\"\u001b[0m                                                              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m4 response = predictor.predict(data=audio_path)                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[96mprint\u001b[0m(json.loads(response))                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m7 \u001b[0m                                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sagemaker/\u001b[0m\u001b[1;33mbase_predictor.py\u001b[0m:\u001b[94m212\u001b[0m in \u001b[92mpredict\u001b[0m               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m inference_component_name:                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   │   \u001b[0mrequest_args[\u001b[33m\"\u001b[0m\u001b[33mInferenceComponentName\u001b[0m\u001b[33m\"\u001b[0m] = inference_component_name              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m211 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m212 \u001b[2m│   │   \u001b[0mresponse = \u001b[96mself\u001b[0m.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**req   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._handle_response(response)                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_handle_response\u001b[0m(\u001b[96mself\u001b[0m, response):                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/botocore/\u001b[0m\u001b[1;33mclient.py\u001b[0m:\u001b[94m570\u001b[0m in \u001b[92m_api_call\u001b[0m                      \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 567 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mpy_operation_name\u001b[33m}\u001b[0m\u001b[33m() only accepts keyword arguments.\u001b[0m\u001b[33m\"\u001b[0m              \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 568 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 569 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m 570 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._make_api_call(operation_name, kwargs)                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 571 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 572 \u001b[0m\u001b[2m│   │   \u001b[0m_api_call.\u001b[91m__name__\u001b[0m = \u001b[96mstr\u001b[0m(py_operation_name)                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 573 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/botocore/\u001b[0m\u001b[1;33mcontext.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mwrapper\u001b[0m                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m start_as_current_context():                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m hook:                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhook()                                                                 \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m124 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m wrapper                                                                     \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m127 \u001b[0m                                                                                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/botocore/\u001b[0m\u001b[1;33mclient.py\u001b[0m:\u001b[94m1031\u001b[0m in \u001b[92m_make_api_call\u001b[0m                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1028 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCode\u001b[0m\u001b[33m\"\u001b[0m                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1029 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1030 \u001b[0m\u001b[2m│   │   │   \u001b[0merror_class = \u001b[96mself\u001b[0m.exceptions.from_code(error_code)                           \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m1031 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m error_class(parsed_response, operation_name)                            \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1032 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1033 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m parsed_response                                                        \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m1034 \u001b[0m                                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModelError: \u001b[0mAn error occurred \u001b[1m(\u001b[0mModelError\u001b[1m)\u001b[0m when calling the InvokeEndpoint operation: Received server error \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m \n",
       "from primary with message \u001b[38;2;0;135;0m\"Your invocation timed out while waiting for a response from container primary. Review \u001b[0m\n",
       "\u001b[38;2;0;135;0mthe latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\"\u001b[0m. See \n",
       "\u001b[4;38;2;0;105;255mhttps://us-west-2.console.aws.amazon.com/cloudwatch/home?\u001b[0m\u001b[4;38;2;0;105;255mregion\u001b[0m\u001b[4;38;2;0;105;255m=\u001b[0m\u001b[4;38;2;0;105;255mus\u001b[0m\u001b[4;38;2;0;105;255m-west-2#logEventViewer:\u001b[0m\u001b[4;38;2;0;105;255mgroup\u001b[0m\u001b[4;38;2;0;105;255m=/aws/sagemaker/Endpo\u001b[0m\n",
       "\u001b[4;38;2;0;105;255mints/pytorch-inference-neuronx-ml-inf2-2025-03-19-11-30-08-598\u001b[0m in account \u001b[1;36m392304288222\u001b[0m for more information.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "audio_path = \"sample_audio.wav\"\n",
    "response = predictor.predict(data=audio_path)\n",
    "\n",
    "print(json.loads(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5e56e-fb10-4c66-af17-e453842b7d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
